{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIo9lOxbttHn"
   },
   "source": [
    " 언어 모델이 해결할 수 있는 것\n",
    "=> 지시만으로 어려운 문제들을 해결 가능\n",
    "=> 번역, 요약, 말투 변경, 작문 등…\n",
    "\n",
    " 언어 모델의 한계\n",
    "=> 학습 지식을 벗어난 정보에 대해서는 답변 불가능\n",
    "\n",
    " 언어 모델의 한계를 벗어나는 방법론들의 등장\n",
    "=> RAG(Retrieval-Augemnted Generation), ReACT(Reasoning and Acting)\n",
    "\n",
    "이러한 방법론들을 적용하면서 언어 모델 애플리케이션 개발: Langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcKA2r9Ktw5V"
   },
   "source": [
    "* Model I/O: 프롬프트 준비, 언어 모델 호출, 결과 수신\n",
    "* Retrieval: 외부 지식을 LLM에 주입. ChatPDF, CSV 파일 기반 답변\n",
    "* Memory: 과거의 대화를 장/단기로 기억. 이전 문맥을 고려한 답변.\n",
    "* Chains: 여러 모듈을 통합하는 기능. 단독 사용 용도 X\n",
    "* Agents: ReACT나 Function Calling 기법을 사용해 외부와 상호 작용.\n",
    "* Callbacks: 다양한 이벤트 발생을 처리 가능. 단독 사용 용도 X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJK78UTsSosU",
    "outputId": "fac0790d-2b08-4429-b094-0fc02d63a204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
      "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain)\n",
      "  Downloading langchain_core-0.3.37-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.3.6-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.37-py3-none-any.whl (413 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.8.0-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-core, langchain-openai, langchain, langchain_community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.35\n",
      "    Uninstalling langchain-core-0.3.35:\n",
      "      Successfully uninstalled langchain-core-0.3.35\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.18\n",
      "    Uninstalling langchain-0.3.18:\n",
      "      Successfully uninstalled langchain-0.3.18\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.19 langchain-core-0.3.37 langchain-openai-0.3.6 langchain_community-0.3.18 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.0 python-dotenv-1.0.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# tiktoken은 Embedding 실습을 위해 필요\n",
    "!pip install openai langchain tiktoken langchain_community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyu4cKnfSw8Z"
   },
   "source": [
    "아래 링크에서 OpenAI API Key를 발급받으세요.  \n",
    "링크: https://platform.openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgYj4EuCStny"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] =  \"여러분의 Key 값\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EgFyGp81TNFU",
    "outputId": "f2d6ba27-4437-447a-e4cd-0b89c81a5a41"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1.57.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii-5UsFPT-ky"
   },
   "source": [
    "# 1. Langchain 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDQu6YzET585"
   },
   "source": [
    "## 1-1. ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxsGOAUpTx7r"
   },
   "source": [
    "OpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\n",
    "\n",
    "객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\n",
    "\n",
    "`temperature`\n",
    "- 사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\n",
    "\n",
    "`max_tokens`\n",
    "- 채팅 완성에서 생성할 토큰의 최대 개수입니다.\n",
    "\n",
    "`model_name`: 적용 가능한 모델 리스트\n",
    "\n",
    "- 링크: https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jppEm1BkTVzK",
    "outputId": "5eccd3ad-ad1a-4957-cecd-d5efd80d937c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: content='세종대왕(1397-1450)은 조선의 제4대 왕으로, 본명은 이도(李祹)입니다. 그는 1418년에 왕위에 올라 1450년까지 통치하였으며, 그의 통치 기간은 조선 역사에서 가장 빛나는 시기로 평가받고 있습니다.\\n\\n세종대왕은 특히 한글, 즉 훈민정음을 창제한 왕으로 유명합니다. 한글은 한국어를 표기하기 위해 만든 문자로, 일반 국민이 쉽게 읽고 쓸 수 있도록 고안되었습니다. 이는 당시의 한자 중심의 문자 체계에서 벗어나, 모든 계층의 사람들이 자신의 언어를 사용할 수 있는 기회를 제공한 혁신적인 업적입니다.\\n\\n그 외에도 세종대왕은 과학, 농업, 음악, 천문학 등 다양한 분야에서 많은 발전을 이끌었습니다. 예를 들어, 그는 측우기(비를 측정하는 기구)와 같은 기구를 개발하고, 농업 기술을 개선하기 위한 여러 정책을 시행했습니다. 또한, 음악과 관련하여 정간보와 같은 악보 체계를 정립하기도 했습니다.\\n\\n세종대왕은 그의 통치 아래에서 문화와 과학이 크게 발전하였고, 백성을 위한 정책을 많이 시행하여 국민의 삶의 질을 향상시켰습니다. 그의 업적은 오늘날까지도 많은 사람들에게 기억되고 있으며, 한국 역사에서 가장 존경받는 왕 중 한 명으로 여겨집니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 326, 'prompt_tokens': 16, 'total_tokens': 342, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None} id='run-368be396-2110-43e5-91d6-9b3a28785a12-0' usage_metadata={'input_tokens': 16, 'output_tokens': 326, 'total_tokens': 342, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"세종대왕이 누구인지 설명해주세요\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.invoke(question)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDzn1U2HUHUf"
   },
   "source": [
    "## 1-2. 프롬프트 템플릿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAVHhjWGUPAK"
   },
   "source": [
    "`PromptTemplate`\n",
    "\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\n",
    "- 사용법\n",
    "- `template`: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\n",
    "- `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- `input_variables`는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\n",
    "- 사용법: 리스트 형식으로 변수 이름을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UkCxiP36Tc95",
    "outputId": "87cc7eb5-8425-4770-c80e-e5e72fb7543a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['who'], input_types={}, partial_variables={}, template='{who}가 누구인지 설명해주세요')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = \"{who}가 누구인지 설명해주세요\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR5kE_oLUdj7"
   },
   "source": [
    "프롬프트 템플릿은 {who}는 빈 칸. 즉, 변할 수 있는 값으로 두고 일종의 템플릿을 만들어두는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slrsQw0AeQTr"
   },
   "source": [
    ".format()을 통해 명시적으로 추가하여 프롬프트 완성본을 미리 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "z7hoth3OeHMU",
    "outputId": "2e12cdd1-add0-40d2-a755-465598575ebc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'오바마가 누구인지 설명해주세요'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(who=\"오바마\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxI5dVHbWLQp"
   },
   "source": [
    "## 1-3. LLMChain 객체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4mStr0iWO7o"
   },
   "source": [
    "`LLMChain`\n",
    "\n",
    "- LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다  \n",
    "\n",
    "사용법\n",
    "- `prompt`: 앞서 정의한 PromptTemplate 객체를 사용합니다.\n",
    "- `llm`: 언어 모델을 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZDh3_KgwWdeP"
   },
   "source": [
    "```\n",
    "코드 예시\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = prompt | llm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhd60yiUWkX-"
   },
   "source": [
    "LLMChain을 사용하기 위해서는 앞서 1.1. ChatOpenAI에서 본 바와 같이 llm이 이미 선언되어져 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Nb4tN1eWNz1"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    ")\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq5f6Oz6WsU0"
   },
   "source": [
    "정리해보면 현재 llm과 프롬프트 템플릿이 chain을 통해 연결된 상태입니다. 다만, 아직 `{who}`는 현재 변수. 즉, 빈 값 상태로 있습니다.  \n",
    "\n",
    "이 빈 값을 채울 때는 invoke() 안에 {\"변수명\": \"변수의 값\"}으로 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFLYarZTXHED"
   },
   "source": [
    "사용 가능한 변수는 `who`밖에 없는데, 임의로 다른 변수에 대해서 값을 넣는 것을 시도해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "wsSPUAXRWzpd",
    "outputId": "aba017b5-6aa3-45f9-d838-e83f80eeb125"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'who'}.  Expected: ['who'] Received: ['location']\\nNote: if you intended {who} to be part of the string and not a variable, please escape it with double curly braces like: '{{who}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-50fffb8b8892>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"서울\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3022\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3024\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m             output = cast(\n\u001b[1;32m   1926\u001b[0m                 \u001b[0mOutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1927\u001b[0;31m                 context.run(\n\u001b[0m\u001b[1;32m   1928\u001b[0m                     \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1929\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_format_prompt_with_error_handling\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_prompt_with_error_handling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0m_inner_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_inner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, inner_input)\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;34mf\"'{{{{{example_key}}}}}'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             )\n\u001b[0;32m--> 176\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    177\u001b[0m                 \u001b[0mcreate_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mErrorCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINVALID_PROMPT_INPUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Input to PromptTemplate is missing variables {'who'}.  Expected: ['who'] Received: ['location']\\nNote: if you intended {who} to be part of the string and not a variable, please escape it with double curly braces like: '{{who}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "llm_chain.invoke({\"location\": \"서울\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQcFwvmuXP7C"
   },
   "source": [
    "Missing some input keys: {'who'}라는 에러가 발생하는데 who에 대한 값을 채우라는 에러입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GwdTyvuXfqI"
   },
   "source": [
    "이제 who에 직접적으로 값을 넣어 정말로 호출해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijeGFDSlXNrC",
    "outputId": "e3003aeb-3469-4132-b1ba-bf82fb9c1e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='세종대왕(1397-1450)은 조선의 제4대 왕으로, 본명은 이도(李祹)입니다. 그는 1418년에 왕위에 올라 1450년까지 통치하였으며, 조선 역사에서 가장 위대한 왕 중 한 사람으로 평가받고 있습니다.\\n\\n세종대왕은 한글, 즉 훈민정음을 창제한 것으로 가장 잘 알려져 있습니다. 한글은 한국어를 표기하기 위해 만든 문자로, 일반 국민들이 쉽게 읽고 쓸 수 있도록 고안되었습니다. 이는 당시 유교적 엘리트 중심의 사회에서 문맹률을 낮추고, 국민의 교육 수준을 높이는 데 큰 기여를 하였습니다.\\n\\n그 외에도 세종대왕은 과학, 농업, 음악, 천문학 등 다양한 분야에서 많은 업적을 남겼습니다. 예를 들어, 그는 측우기(비를 측정하는 기구)와 같은 기계를 발명하고, 농업 기술을 발전시켜 농민들의 삶을 개선하려고 노력했습니다. 또한, 천문학적 관측을 통해 별자리와 달력을 정리하는 등의 작업도 수행했습니다.\\n\\n세종대왕은 인재를 중시하고, 백성을 사랑하는 통치자로서, 그의 통치 기간은 조선의 문화와 과학이 발전한 황금기로 여겨집니다. 그의 업적은 오늘날에도 많은 사람들에게 기억되고 있으며, 한국의 역사와 문화에 큰 영향을 미쳤습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 326, 'prompt_tokens': 16, 'total_tokens': 342, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-1c013ccd-721e-49f9-ba1b-5934edd506df-0', usage_metadata={'input_tokens': 16, 'output_tokens': 326, 'total_tokens': 342, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"who\": \"세종대왕\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2JO_Eko_Xdy1",
    "outputId": "0d16d498-23eb-410c-999e-8a1bbf117c36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"이순신(李舜臣, 1545-1598)은 조선 중기의 군인으로, 임진왜란(1592-1598) 동안 일본의 침략에 맞서 싸운 대표적인 장군입니다. 그는 특히 해군의 지휘관으로서 뛰어난 전략과 전술로 유명하며, 그의 전투 중 가장 잘 알려진 것은 명량 해전과 한산도 해전입니다.\\n\\n이순신은 조선의 해군을 강화하고, 철갑선인 판옥선을 개발하여 해상 전투에서의 우위를 점했습니다. 그의 전투에서의 승리는 조선의 국방에 큰 기여를 하였고, 그는 조선의 역사에서 가장 존경받는 인물 중 하나로 평가받고 있습니다.\\n\\n그의 업적은 단순히 군사적 승리에 그치지 않고, 충성과 희생정신, 그리고 국가에 대한 헌신으로도 많은 사람들에게 귀감이 되고 있습니다. 이순신은 또한 '난중일기'라는 일기를 남겨, 전쟁의 상황과 자신의 생각을 기록하여 후세에 중요한 역사적 자료로 남겼습니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 249, 'prompt_tokens': 17, 'total_tokens': 266, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_6fc10e10eb', 'finish_reason': 'stop', 'logprobs': None}, id='run-74e20ce0-1023-44e3-a084-4671b813966b-0', usage_metadata={'input_tokens': 17, 'output_tokens': 249, 'total_tokens': 266, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"who\": \"이순신 장군\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT68fPxkbxrx"
   },
   "source": [
    "과금 구조: https://openai.com/pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMPV_CtNb0W1"
   },
   "source": [
    "### 1-3-1. 2개 이상의 변수를 템플릿 안에 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAFvMqTwcSDt"
   },
   "source": [
    "변수가 2개 이상이라는 것 외에는 위에서 실습한 것과 사용 방법은 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-nsqXkScPG9"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4922sD9KbsJR",
    "outputId": "bcf7652d-988d-4259-f868-0a608276af0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['time1', 'time2'], input_types={}, partial_variables={}, template='{time1}에서 가장 용맹한 위인과 {time2}에서 가장 용맹한 위인은 누구인지 궁금해')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문 템플릿 형식 정의\n",
    "template = \"{time1}에서 가장 용맹한 위인과 {time2}에서 가장 용맹한 위인은 누구인지 궁금해\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Tz6nWvGcL-J"
   },
   "outputs": [],
   "source": [
    "# llm 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Kjg4aAkcJZA"
   },
   "outputs": [],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DW_8CU1LcG0Z",
    "outputId": "409616ec-2352-4a4c-a1f3-983e3558016f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['time1', 'time2'], input_types={}, partial_variables={}, template='{time1}에서 가장 용맹한 위인과 {time2}에서 가장 용맹한 위인은 누구인지 궁금해')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7c6944305630>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7c692b921ed0>, root_client=<openai.OpenAI object at 0x7c692b8c0bb0>, root_async_client=<openai.AsyncOpenAI object at 0x7c69443059c0>, temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'), max_tokens=2048)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48Fl5FwXcVua",
    "outputId": "93a920e9-c621-47b4-acb6-c43769962524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='고려에서 가장 용맹한 위인으로는 김유신이 유명합니다. 그는 고려의 장군으로서 많은 전투에서 승리를 거두었고, 고려의 안정과 번영을 위해 헌신한 위인으로 평가받고 있습니다.\\n\\n조선에서 가장 용맹한 위인으로는 이순신 장군이 유명합니다. 그는 조선의 해상 전투에서 맹활약하여 일본의 침략을 막는 데 큰 공헌을 하였으며, 조선의 해군을 발전시키고 국가를 지키는 데 헌신한 위인으로 평가받고 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 212, 'prompt_tokens': 47, 'total_tokens': 259, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-eec911b4-14db-4d25-8d13-205b7c4201de-0' usage_metadata={'input_tokens': 47, 'output_tokens': 212, 'total_tokens': 259, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain.invoke({\"time1\": \"고려\", \"time2\": \"조선\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnmJ-Tbqc11Z"
   },
   "source": [
    "### 1-3-2. Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TckrzZ4ec4om"
   },
   "source": [
    "다음과 같이 streaming=True 로 설정하고 스트리밍으로 답변을 받기 위한 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXBSBVy8cvAI"
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zEjCKzTvc6px",
    "outputId": "7a3372bc-5a17-4d78-b1a6-ea2ae822a7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세종대왕의 본명은 이도입니다. 그러나 그는 세종대왕으로 더 잘 알려져 있습니다."
     ]
    }
   ],
   "source": [
    "# 질의내용\n",
    "question = \"세종대왕의 이름을 알려줘\"\n",
    "\n",
    "# 스트리밍으로 답변 출력\n",
    "response = llm.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xkoz0QoAd5_N"
   },
   "source": [
    "## 1-4. 프롬프트 템플릿 심화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QFDv5wBey1e"
   },
   "source": [
    "### 1-4-1. 함수를 프롬프트로 전달"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGk6nb2Pe3Je"
   },
   "source": [
    "시간이나 날짜에 따라서 프롬프트가 매일 변경되어야 한다면 함수 자체를 프롬프트와 연결할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cIV6WkHoc9PQ",
    "outputId": "52d9c0d2-205b-443e-a7a3-41bff4266576"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'December 14'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 월 일 형식으로 오늘 날짜를 반환하는 함수\n",
    "def get_today():\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%B %d\")\n",
    "\n",
    "get_today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3mERIJRfAbd"
   },
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    template=\"오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\"today\": get_today},  # partial_variables에 함수를 전달\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_Ow0tJQfCNX",
    "outputId": "3f9ba371-37fa-4b9b-ed3a-ac6196020c92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['n'], input_types={}, partial_variables={'today': <function get_today at 0x7c692b8b96c0>}, template='오늘의 날짜는 {today} 입니다. 오늘이 생일인 유명인 {n}명을 나열해 주세요.')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNGLV8EHfJLf"
   },
   "source": [
    "위에서 프롬프트에서 변수는 {today}와 {n}이지만 partial_variable을 보면 'today'의 값으로는 함수가 전달된 상태로 n의 값은 전달되지 않은 상태이다. .format()을 통해서 n의 값을 마저 전달하면 최종 프롬프트가 완성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "VlebczvUfRte",
    "outputId": "2784d495-c00a-44ce-9fbc-ad5707b3eafd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'오늘의 날짜는 December 14 입니다. 오늘이 생일인 유명인 5명을 나열해 주세요.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.format(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-M9kJBih9NJ"
   },
   "source": [
    "# 2. 유틸리티"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey9J-FsIDWeE"
   },
   "source": [
    "## 2-1. 캐싱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T0Rz1oMCNL0"
   },
   "source": [
    "https://python.langchain.com/docs/modules/model_io/llms/llm_caching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxHvUWdZh_i8"
   },
   "source": [
    "LangChain은 LLM을 위한 선택적 캐싱 레이어를 제공합니다.\n",
    "\n",
    "이는 두 가지 이유로 유용합니다:\n",
    "\n",
    "- 동일한 완료를 여러 번 요청하는 경우 LLM 공급자에 대한 API 호출 횟수를 줄여 비용을 절감 할 수 있습니다.\n",
    "- LLM 제공업체에 대한 API 호출 횟수를 줄여 애플리케이션의 속도를 높일 수 있습니다.  \n",
    "\n",
    "모델과 프롬프트를 생성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "knf3hO4sh-Rj",
    "outputId": "9d759e19-4a44-461b-ae77-c40845bd6ac3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['who'], input_types={}, partial_variables={}, template='{who} 에 대해서 짧게 설명해줘')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "### 캐시 사용을 위한 코드 추가 ###\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "set_llm_cache(InMemoryCache())\n",
    "### 캐시 사용을 위한 코드 추가 ###\n",
    "\n",
    "# llm 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(\"{who} 에 대해서 짧게 설명해줘\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNCcgqZ0iJmh"
   },
   "outputs": [],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxr2ADLBB25H"
   },
   "source": [
    "코드 앞에 %%time을 함께 사용해서 실행하면 소요 시간을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NacYxmCBGjc",
    "outputId": "c0fc6c60-b634-436a-d3f3-07467ed67c91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.7 ms, sys: 3.08 ms, total: 24.8 ms\n",
      "Wall time: 2.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='세종대왕은 조선시대 4대 왕 중 하나로, 조선시대를 대표하는 왕으로 꼽힙니다. 세종대왕은 한글을 창제하고 학문과 문화를 발전시키는 데 큰 공헌을 한 위인으로 알려져 있습니다. 또한 세종대왕은 국방력을 강화하고 행정체제를 정비하여 조선시대의 번영을 이룩하는 데 기여한 위인으로 평가받고 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 25, 'total_tokens': 186, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-41757f57-0cec-413d-94f2-f89338938bf9-0', usage_metadata={'input_tokens': 25, 'output_tokens': 161, 'total_tokens': 186, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm_chain.invoke({\"who\": \"세종대왕\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMxT-GP6B7HU"
   },
   "source": [
    "현재 캐시가 동작 중이므로 동일한 호출을 다시 해보겠습니다. 캐시가 동작하여 동일한 질문에 대해서는 동일한 답변을 빠르게 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5DrVDT5B0kV",
    "outputId": "0380a6fc-4a2f-467b-83ff-ec04027d6055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 987 µs, sys: 0 ns, total: 987 µs\n",
      "Wall time: 966 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='세종대왕은 조선시대 4대 왕 중 하나로, 조선시대를 대표하는 왕으로 꼽힙니다. 세종대왕은 한글을 창제하고 학문과 문화를 발전시키는 데 큰 공헌을 한 위인으로 알려져 있습니다. 또한 세종대왕은 국방력을 강화하고 행정체제를 정비하여 조선시대의 번영을 이룩하는 데 기여한 위인으로 평가받고 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 25, 'total_tokens': 186, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-41757f57-0cec-413d-94f2-f89338938bf9-0', usage_metadata={'input_tokens': 25, 'output_tokens': 161, 'total_tokens': 186, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm_chain.invoke({\"who\": \"세종대왕\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZmW7L6bCJ_8"
   },
   "source": [
    "## 2-2. 토큰 사용량 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx7X41RLCk8Y"
   },
   "source": [
    "https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzAglMIICtYv"
   },
   "source": [
    "get_openai_callback을 이용하여 토큰 사용량을 추적할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yo_1TUNCbQw"
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3j1uVKv0CqB_",
    "outputId": "ad9fc48e-b9f8-487c-c2e1-b5b91e91ce7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 82\n",
      "\tPrompt Tokens: 19\n",
      "\tCompletion Tokens: 63\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00010400000000000001\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"안녕 너는 누구야\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58tzul8SCwwv",
    "outputId": "5dc9b295-ac7e-4d1f-edbc-e4f9844e1da9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕, 나는 인공지능 기반 챗봇이야. 너의 질문에 답변해주는데 도움을 줄 수 있어. 무엇을 도와줄까?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 19, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b32b7329-6076-4ae0-9fac-6b406df7de02-0', usage_metadata={'input_tokens': 19, 'output_tokens': 63, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmI3m0EqNYTE"
   },
   "source": [
    "# 3. 입력 프롬프트 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WgKIBJCNgN4"
   },
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4qdzB3SN9fK",
    "outputId": "b6cfa53f-3021-4965-9273-d81df2e823ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['who'], input_types={}, partial_variables={}, template='{who} 에 대해서 짧게 설명해줘')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "# 프롬프트 생성\n",
    "prompt = PromptTemplate.from_template(\"{who} 에 대해서 짧게 설명해줘\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b3QHxvzrODPX"
   },
   "outputs": [],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEO0NbtpOObv",
    "outputId": "e3a9385d-901a-4b07-a82b-1be7c9706e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"who\": \"이순신 장군\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"who\": \"이순신 장군\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 이순신 장군 에 대해서 짧게 설명해줘\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.94s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"이순신 장군은 조선시대의 무신이자 민족영웅으로, 조선의 해군을 이끌었던 뛰어난 무장력을 가진 장수입니다. 일본의 침략을 막기 위해 전쟁을 치르고, 명량 해전에서 일본 함대를 물리치는 등 업적을 남겼습니다. 그의 뛰어난 전략과 무기력으로 많은 사람들에게 존경받고 있습니다.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"이순신 장군은 조선시대의 무신이자 민족영웅으로, 조선의 해군을 이끌었던 뛰어난 무장력을 가진 장수입니다. 일본의 침략을 막기 위해 전쟁을 치르고, 명량 해전에서 일본 함대를 물리치는 등 업적을 남겼습니다. 그의 뛰어난 전략과 무기력으로 많은 사람들에게 존경받고 있습니다.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 157,\n",
      "                \"prompt_tokens\": 27,\n",
      "                \"total_tokens\": 184,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-9d058b88-cdbb-4b70-849f-f365393627c9-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 27,\n",
      "              \"output_tokens\": 157,\n",
      "              \"total_tokens\": 184,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 157,\n",
      "      \"prompt_tokens\": 27,\n",
      "      \"total_tokens\": 184,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.94s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "# invoke()를 할 때 , config={'callbacks': [ConsoleCallbackHandler()]}를 함께 전달하면 입력 프롬프트까지 출력\n",
    "result = llm_chain.invoke({\"who\":\"이순신 장군\"}, config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyn7mr42ObSk",
    "outputId": "629d3386-c6e3-4cb7-d333-66eef941a0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='이순신 장군은 조선시대의 무신이자 민족영웅으로, 조선의 해군을 이끌었던 뛰어난 무장력을 가진 장수입니다. 일본의 침략을 막기 위해 전쟁을 치르고, 명량 해전에서 일본 함대를 물리치는 등 업적을 남겼습니다. 그의 뛰어난 전략과 무기력으로 많은 사람들에게 존경받고 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 157, 'prompt_tokens': 27, 'total_tokens': 184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9d058b88-cdbb-4b70-849f-f365393627c9-0' usage_metadata={'input_tokens': 27, 'output_tokens': 157, 'total_tokens': 184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SxvBBwxOiPc",
    "outputId": "49e3345c-1458-49c5-a677-9f49f5018879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이순신 장군은 조선시대의 무신이자 민족영웅으로, 조선의 해군을 이끌었던 뛰어난 무장력을 가진 장수입니다. 일본의 침략을 막기 위해 전쟁을 치르고, 명량 해전에서 일본 함대를 물리치는 등 업적을 남겼습니다. 그의 뛰어난 전략과 무기력으로 많은 사람들에게 존경받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XXVp35vDqzT"
   },
   "source": [
    "# 3. 메모리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjA9XWLJFWJs"
   },
   "source": [
    "ChatGPT와 대화하면 현재의 대화를 이어나갈 때 과거의 대화를 기반으로 대화하는 것을 느낄 수 있습니다.\n",
    "\n",
    "대부분의 LLM(Large Language Models) 애플리케이션은 대화형 인터페이스를 가지고 있습니다. 대화의 중요한 구성 요소 중 하나는 이전 대화에 있는 정보를 참조할 수 있는 능력입니다.\n",
    "\n",
    "이전 대화에서 주요한 정보를 기억할 수 있는 이 능력을 우리는 \"메모리(memory)\"라고 부릅니다. LangChain은 시스템에 메모리를 추가하기 위한 다양한 유틸리티를 제공합니다. 이러한 유틸리티는 단독으로 사용될 수 있으며 체인(chain)에 원활하게 통합될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-q1srb15yuul"
   },
   "source": [
    "## 3-1. RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmDsC_53S_Cq",
    "outputId": "24c56c8d-5191-49f7-bdfa-d8976744b7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['history', 'input'] input_types={} partial_variables={} template='당신은 위키북스에서 만든 친절한 위키봇입니다. 누가 당신에게 누구냐고 묻거든 위키북스에서 만든 위키봇이라고 소개하세요.\\n그 외의 답변은 최선을 다해서 친절하게 답변하세요.\\n\\nCurrent Conversation: {history}\\n\\nHuman: {input}\\n\\nAI:'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# llm 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-4o\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template= \"\"\"당신은 위키북스에서 만든 친절한 위키봇입니다. 누가 당신에게 누구냐고 묻거든 위키북스에서 만든 위키봇이라고 소개하세요.\n",
    "그 외의 답변은 최선을 다해서 친절하게 답변하세요.\n",
    "\n",
    "Current Conversation: {history}\n",
    "\n",
    "Human: {input}\n",
    "\n",
    "AI:\"\"\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate(\n",
    "        template=template, input_variables=['history', 'input']\n",
    "    )\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hnVVIzfTFTL"
   },
   "outputs": [],
   "source": [
    "# Chat History를 저장할 store 딕셔너리를 생성\n",
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHg_TEpRTQfn"
   },
   "outputs": [],
   "source": [
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U82L-8NZThWA"
   },
   "outputs": [],
   "source": [
    "# 세션 ID를 생성. 여기서는 임의로 \"test\"로 지정합니다.\n",
    "session_id = \"test\"\n",
    "\n",
    "# 만약 현재 생성한 세션 ID가 기존에 존재하지 않는다면 store에 추가\n",
    "if session_id not in store:\n",
    "    store[session_id] = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7uOYfRG0T4RZ",
    "outputId": "640524fa-3890-4d97-98ea-fc677d9fda5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': InMemoryChatMessageHistory(messages=[])}\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-qq-bgfUEV2"
   },
   "source": [
    "store 딕셔너리에 \"test\"를 key로 하고 InMemoryChatMessageHistory()를 value로 하는 원소가 추가된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qczJmZXT3pR"
   },
   "outputs": [],
   "source": [
    "session_history = store[session_id]  # 안전하게 세션 기록을 변수에 할당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW0wx6avUdgY"
   },
   "source": [
    "store[session_id]를 이번에는 session_history에 저장해서 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AW3-1IwdUY-D",
    "outputId": "cd5f305d-854e-4d95-b524-7529ae8e89f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s72fwRCWwyo"
   },
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    llm_chain,\n",
    "    lambda session_id: session_history,  # 직접 참조를 반환하도록 수정\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNz78UEXZ8be"
   },
   "source": [
    "이때 \"test\"라는 세션 내에서 과거 대화가 관리되므로 \"test\"라고 호출한 대화 한정으로는 과거 대화를 관리할 수 있다.  \n",
    "invoke() 시에 config={\"configurable\": {\"session_id\": \"test\"}를 같이 넣어서 호출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYG-70zLW8rk",
    "outputId": "fdb8ebe7-a13e-4359-b9d7-c2eb9dae04cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='저는 위키북스에서 만든 친절한 위키봇입니다. 무엇을 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 81, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None} id='run-b87fae0f-f84e-4548-820a-4415f8a1bf4e-0' usage_metadata={'input_tokens': 81, 'output_tokens': 25, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 주어진 메시지와 설정으로 체인을 실행합니다.\n",
    "result = with_message_history.invoke(\n",
    "    {\"input\": \"당신은 누구입니까?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test\"}},\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgleMb-qaUCl",
    "outputId": "7970b158-f3e0-449d-a043-481e04a98095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 위키북스에서 만든 친절한 위키봇입니다. 무엇을 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7OLZXEHZJ8t"
   },
   "source": [
    "Warning은 신경쓰지 않아도 됩니다. (https://github.com/langchain-ai/langchain/issues/24713)  \n",
    "\n",
    "출력 결과를 보면 당신은 누구냐는 질문에 '위키북스에서 만든 위키봇'이라는 답변을 한다.  \n",
    "session_history를 출력해보면 현재의 질답이 저장되어져 있는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9a724eUZZFj",
    "outputId": "ac8d2e74-8b7f-4d42-b5cb-40446fb84b9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='당신은 누구입니까?', additional_kwargs={}, response_metadata={}), AIMessage(content='저는 위키북스에서 만든 친절한 위키봇입니다. 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 81, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None}, id='run-b87fae0f-f84e-4548-820a-4415f8a1bf4e-0', usage_metadata={'input_tokens': 81, 'output_tokens': 25, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDjpql8KZlu6"
   },
   "source": [
    "store dictionary에도 'test'를 key 값으로 히스토리가 저장되어져 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBdwOIXfZjOl",
    "outputId": "751e0349-7770-4018-cbea-09e64825c7cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': InMemoryChatMessageHistory(messages=[HumanMessage(content='당신은 누구입니까?', additional_kwargs={}, response_metadata={}), AIMessage(content='저는 위키북스에서 만든 친절한 위키봇입니다. 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 81, 'total_tokens': 106, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None}, id='run-b87fae0f-f84e-4548-820a-4415f8a1bf4e-0', usage_metadata={'input_tokens': 81, 'output_tokens': 25, 'total_tokens': 106, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHgW9SYBZ6jm",
    "outputId": "61f22d19-1807-4157-856c-d72dde0fca0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"물론이죠! '홍길동'으로 삼행시를 지어볼게요.\\n\\n홍: 홍익인간의 정신을 품고,  \\n길: 길을 잃지 않고 바르게 나아가며,  \\n동: 동서남북 어디서든 빛나는 사람이 되자.  \\n\\n어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 363, 'total_tokens': 448, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None} id='run-b37e88c4-bc7d-4fd7-b8c7-df71813366ed-0' usage_metadata={'input_tokens': 363, 'output_tokens': 85, 'total_tokens': 448, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"input\": \"'홍길동'으로 삼행시 해줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test\"}},\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LGy2GZesaKFz",
    "outputId": "a81991f9-99ae-4f50-ea19-d9cee88341da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! '홍길동'으로 삼행시를 지어볼게요.\n",
      "\n",
      "홍: 홍익인간의 정신을 품고,  \n",
      "길: 길을 잃지 않고 바르게 나아가며,  \n",
      "동: 동서남북 어디서든 빛나는 사람이 되자.  \n",
      "\n",
      "어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fk0AfnszaarB",
    "outputId": "b4c39c12-1d4c-4fcc-961d-70d8556d7cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"물론이죠! 감성적인 느낌으로 '홍길동' 삼행시를 지어볼게요.\\n\\n홍: 홍조 띤 하늘 아래,  \\n길: 길게 드리운 그림자 속에서,  \\n동: 동화 같은 꿈을 꾸는 우리.  \\n\\n어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 79, 'prompt_tokens': 708, 'total_tokens': 787, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_9faba9f038', 'finish_reason': 'stop', 'logprobs': None} id='run-430fa74f-7e29-4fc9-81a5-fe92c2a45bcd-0' usage_metadata={'input_tokens': 708, 'output_tokens': 79, 'total_tokens': 787, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "result = with_message_history.invoke(\n",
    "    {\"input\": \"좀 감성적인 느낌으로 해줘\"},\n",
    "    config={\"configurable\": {\"session_id\": \"test\"}},\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-XrFGvyakBj",
    "outputId": "d04f698d-1915-4a75-df80-e246021eb8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론이죠! 감성적인 느낌으로 '홍길동' 삼행시를 지어볼게요.\n",
      "\n",
      "홍: 홍조 띤 하늘 아래,  \n",
      "길: 길게 드리운 그림자 속에서,  \n",
      "동: 동화 같은 꿈을 꾸는 우리.  \n",
      "\n",
      "어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpkSx71Kygxs",
    "outputId": "d31360a1-8138-4aaf-857d-27936b55209f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 히스토리:\n",
      "HumanMessage: 당신은 누구입니까?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AIMessage: 저는 위키북스에서 만든 친절한 위키봇입니다. 무엇을 도와드릴까요?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "HumanMessage: '홍길동'으로 삼행시 해줘\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AIMessage: 물론이죠! '홍길동'으로 삼행시를 지어볼게요.\n",
      "\n",
      "홍: 홍익인간의 정신을 품고,  \n",
      "길: 길을 잃지 않고 바르게 나아가며,  \n",
      "동: 동서남북 어디서든 빛나는 사람이 되자.  \n",
      "\n",
      "어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "HumanMessage: 좀 감성적인 느낌으로 해줘\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AIMessage: 물론이죠! 감성적인 느낌으로 '홍길동' 삼행시를 지어볼게요.\n",
      "\n",
      "홍: 홍조 띤 하늘 아래,  \n",
      "길: 길게 드리운 그림자 속에서,  \n",
      "동: 동화 같은 꿈을 꾸는 우리.  \n",
      "\n",
      "어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"메시지 히스토리:\")\n",
    "for message in session_history.messages:\n",
    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
    "    print('--' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra11DYMWp4Lk"
   },
   "source": [
    "## 3-2. RunnableWithMessageHistory (top=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBTPm3lcyzSY"
   },
   "source": [
    "위의 RunnableWithMessageHistory를 사용하면 과거 대화가 무한정 누적될 수 있습니다. 이렇게 되면 대화를 여러 번할수록 입력 프롬프트의 길이가 무한정 늘어날 수 있기 때문에 일반적으로 최근 대화만 기억하도록 하기도 합니다.  \n",
    "\n",
    "여기서는 \"limited_chat_history\"라는 세션 id를 사용하여 최대 몇 개까지의 대화만 기억할지 컨트롤 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "830tjYy_4vBb"
   },
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import List\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "class LimitedChatMessageHistory(BaseChatMessageHistory):\n",
    "    def __init__(self, max_conversations: int = 2):\n",
    "        self.full_messages: List[BaseMessage] = []\n",
    "        self.messages: List[BaseMessage] = []\n",
    "\n",
    "        # max_converstion은 기억할 대화의 개수. 만약 -1을 해주지 않으면 max_conversations=2를 넣었을 때 과거 대화 2개랑 현재 대화 1개로 3개를 기억한다.\n",
    "        # 하지만 -1을 해주면 max_conversations=2를 넣었을 때 과거 대화 1개, 현재 대화 1개 총 2개를 기억하게 된다.\n",
    "        # 각 대화는 사용자 입력과 AI 응답으로 구성하므로 *2\n",
    "        self.max_messages = (max_conversations -1) * 2\n",
    "\n",
    "    def add_message(self, message: BaseMessage) -> None:\n",
    "        self.full_messages.append(message)\n",
    "        self.messages.append(message)\n",
    "        if len(self.messages) > self.max_messages:\n",
    "            self.messages.pop(0)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.messages = []\n",
    "        self.total_messages = 0\n",
    "\n",
    "    def get_messages(self) -> List[BaseMessage]:\n",
    "        # session_history.messages로 출력할 경우 실제 호출한 것에서 과거 대화가 하나 빠지고 출력된다.\n",
    "        # 따라서 -2를 추가하여 과거 대화 1개를 다시 포함하여 출력 하도록한다. -2인 이유는 사용자 질문, AI 답변 이렇게 2개가 한 쌍의 대화이기 때문이다.\n",
    "        return self.full_messages[-self.max_messages-2:]\n",
    "\n",
    "# 메시지 히스토리를 저장할 딕셔너리\n",
    "session_id = \"limited_chat_history\"\n",
    "message_store = {}\n",
    "message_store[session_id] = LimitedChatMessageHistory(max_conversations=2)\n",
    "\n",
    "chain_with_chat_history = RunnableWithMessageHistory(\n",
    "    llm_chain,\n",
    "    lambda session_id: message_store[session_id],\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "\n",
    "session_history = message_store[session_id]\n",
    "\n",
    "# Example usage\n",
    "result1 = chain_with_chat_history.invoke(\n",
    "    {\"input\": \"너는 누구\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "\n",
    "result2 = chain_with_chat_history.invoke(\n",
    "    {\"input\": \"홍길동으로 시를 지어볼래?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "\n",
    "result3 = chain_with_chat_history.invoke(\n",
    "    {\"input\": \"더 감성적으로 지어볼래?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")\n",
    "\n",
    "result4 = chain_with_chat_history.invoke(\n",
    "    {\"input\": \"현재 대화에서 내가 너한테 던진 첫번째 질문이 뭐였는지 알려줘\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GO4nWz_R_PZ9",
    "outputId": "c3d443be-e0a5-4378-b717-734ef6520025"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='더 감성적으로 지어볼래?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='물론이죠! 홍길동을 주제로 한 감성적인 시를 지어보겠습니다.\\n\\n---\\n\\n달빛 아래 홀로 서서  \\n바람에 실려오는 옛 노래,  \\n홍길동의 마음속 깊은 곳에  \\n그리움이 피어오르네.\\n\\n자유를 꿈꾸며 떠난 길,  \\n별빛이 길을 비추고,  \\n그의 발걸음마다  \\n희망의 꽃이 피어나네.\\n\\n세상은 여전히 어둡지만,  \\n그의 눈에는 빛이 가득,  \\n모두의 마음속에 남을  \\n영원한 영웅, 홍길동이여.\\n\\n---\\n\\n어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 164, 'prompt_tokens': 469, 'total_tokens': 633, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f785eb5f47', 'finish_reason': 'stop', 'logprobs': None}, id='run-0f8e9e53-4268-48ea-8ef0-1eb3749d55c2-0', usage_metadata={'input_tokens': 469, 'output_tokens': 164, 'total_tokens': 633, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='현재 대화에서 내가 너한테 던진 첫번째 질문이 뭐였는지 알려줘', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='당신이 저에게 던진 첫 번째 질문은 \"더 감성적으로 지어볼래?\"였습니다. 더 궁금한 점이 있으면 언제든지 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 547, 'total_tokens': 586, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a79d8dac1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-0591e480-ebb0-4dd1-8992-2b5b1e10467f-0', usage_metadata={'input_tokens': 547, 'output_tokens': 39, 'total_tokens': 586, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_history.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JR2KaHt39k2I",
    "outputId": "cc486040-37ac-4b8e-cdf4-aeac30293487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메시지 히스토리:\n",
      "HumanMessage: 더 감성적으로 지어볼래?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AIMessage: 물론이죠! 홍길동을 주제로 한 감성적인 시를 지어보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "달빛 아래 홀로 서서  \n",
      "바람에 실려오는 옛 노래,  \n",
      "홍길동의 마음속 깊은 곳에  \n",
      "그리움이 피어오르네.\n",
      "\n",
      "자유를 꿈꾸며 떠난 길,  \n",
      "별빛이 길을 비추고,  \n",
      "그의 발걸음마다  \n",
      "희망의 꽃이 피어나네.\n",
      "\n",
      "세상은 여전히 어둡지만,  \n",
      "그의 눈에는 빛이 가득,  \n",
      "모두의 마음속에 남을  \n",
      "영원한 영웅, 홍길동이여.\n",
      "\n",
      "---\n",
      "\n",
      "어떠신가요? 더 도와드릴 것이 있으면 말씀해 주세요!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "HumanMessage: 현재 대화에서 내가 너한테 던진 첫번째 질문이 뭐였는지 알려줘\n",
      "----------------------------------------------------------------------------------------------------\n",
      "AIMessage: 당신이 저에게 던진 첫 번째 질문은 \"더 감성적으로 지어볼래?\"였습니다. 더 궁금한 점이 있으면 언제든지 말씀해 주세요!\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 메시지 히스토리 출력\n",
    "print(\"메시지 히스토리:\")\n",
    "# for message in session_history.messages:\n",
    "for message in session_history.get_messages():\n",
    "    print(f\"{message.__class__.__name__}: {message.content}\")\n",
    "    print('--' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQbOx560To_q"
   },
   "source": [
    "# 4. Text Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YknIU2uaNV8"
   },
   "source": [
    "## 4-1. RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giCHvbasbRn3"
   },
   "source": [
    "이 텍스트 분할기는 일반적인 텍스트에 권장되는 방식입니다.  \n",
    "이 분할기는 문자 목록을 매개변수로 받아 동작합니다.  \n",
    "\n",
    "분할기는 청크가 충분히 작아질 때까지 주어진 문자 목록의 순서대로 텍스트를 분할하려고 시도합니다.  \n",
    "\n",
    "기본 문자 목록은 [\"\\n\\n\", \"\\n\", \" \", \"\"]입니다.  \n",
    "\n",
    "단락 -> 문장 -> 단어 순서로 재귀적으로 분할합니다.  \n",
    "이는 단락(그 다음으로 문장, 단어) 단위가 의미적으로 가장 강하게 연관된 텍스트 조각으로 간주되므로, 가능한 한 함께 유지하려는 효과가 있습니다.  \n",
    "\n",
    "텍스트가 분할되는 방식: 문자 목록([\"\\n\\n\", \"\\n\", \" \", \"\"]) 에 의해 분할됩니다.  \n",
    "\n",
    "청크 크기가 측정되는 방식: 문자 수에 의해 측정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0OLvN7CSx8S"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5iRO9aMbQN1"
   },
   "source": [
    "- chunk_size 매개변수를 3000 으로 설정하여 각 청크의 최대 크기를 3000자로 제한합니다.\n",
    "- chunk_overlap 매개변수를 0으로 설정하여 인접한 청크 간에 중복은 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWoRpqA-YKah"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeGuSfGXX8Rr",
    "outputId": "acce0612-6392-4deb-b5d5-fa820313b5a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-14 16:16:46--  https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 43694449 (42M) [text/plain]\n",
      "Saving to: ‘2016-10-20.txt’\n",
      "\n",
      "2016-10-20.txt      100%[===================>]  41.67M  54.5MB/s    in 0.8s    \n",
      "\n",
      "2024-12-14 16:16:49 (54.5 MB/s) - ‘2016-10-20.txt’ saved [43694449/43694449]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mllosDk8X8qy"
   },
   "outputs": [],
   "source": [
    "with open(\"2016-10-20.txt\") as f:\n",
    "    file = f.read()  # 파일의 내용을 읽어서 file 변수에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "_aqLz1fAYFYl",
    "outputId": "8c4a3cf5-f712-4d0b-c2f0-7ff0d37704e9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' \\n19  1990  52 1 22\\n오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Gg4BOt2YGp7",
    "outputId": "cae56858-6e50-4f04-f28d-50fc2b96542c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25281"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([file])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9aRgd3dadlJ",
    "outputId": "0b18a042-3bf0-40f0-87b2-c5dbc215e56a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8N1Lh0lbWLS",
    "outputId": "f49b7ab8-b49b-4a61-efb2-27582ba2b21b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39n1-FtoafCS"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxn-irdmbbTB",
    "outputId": "6c0da245-bb85-4c29-9caf-248c33cee6c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25416"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = text_splitter.create_documents([file])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BA2-9bi-bcr8",
    "outputId": "7359b23c-9769-4225-db55-66362c3aaffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='오패산터널 총격전 용의자 검거 서울 연합뉴스 경찰 관계자들이 19일 오후 서울 강북구 오패산 터널 인근에서 사제 총기를 발사해 경찰을 살해한 용의자 성모씨를 검거하고 있다 성씨는 검거 당시 서바이벌 게임에서 쓰는 방탄조끼에 헬멧까지 착용한 상태였다 독자제공 영상 캡처 연합뉴스  서울 연합뉴스 김은경 기자 사제 총기로 경찰을 살해한 범인 성모 46 씨는 주도면밀했다  경찰에 따르면 성씨는 19일 오후 강북경찰서 인근 부동산 업소 밖에서 부동산업자 이모 67 씨가 나오기를 기다렸다 이씨와는 평소에도 말다툼을 자주 한 것으로 알려졌다  이씨가 나와 걷기 시작하자 성씨는 따라가면서 미리 준비해온 사제 총기를 이씨에게 발사했다 총알이 빗나가면서 이씨는 도망갔다 그 빗나간 총알은 지나가던 행인 71 씨의 배를 스쳤다  성씨는 강북서 인근 치킨집까지 이씨 뒤를 쫓으며 실랑이하다 쓰러뜨린 후 총기와 함께 가져온 망치로 이씨 머리를 때렸다  이 과정에서 오후 6시 20분께 강북구 번동 길 위에서 사람들이 싸우고 있다 총소리가 났다 는 등의 신고가 여러건 들어왔다  5분 후에 성씨의 전자발찌가 훼손됐다는 신고가 보호관찰소 시스템을 통해 들어왔다 성범죄자로 전자발찌를 차고 있던 성씨는 부엌칼로 직접 자신의 발찌를 끊었다  용의자 소지 사제총기 2정 서울 연합뉴스 임헌정 기자 서울 시내에서 폭행 용의자가 현장 조사를 벌이던 경찰관에게 사제총기를 발사해 경찰관이 숨졌다 19일 오후 6시28분 강북구 번동에서 둔기로 맞았다 는 폭행 피해 신고가 접수돼 현장에서 조사하던 강북경찰서 번동파출소 소속 김모 54 경위가 폭행 용의자 성모 45 씨가 쏜 사제총기에 맞고 쓰러진 뒤 병원에 옮겨졌으나 숨졌다 사진은 용의자가 소지한 사제총기  신고를 받고 번동파출소에서 김창호 54 경위 등 경찰들이 오후 6시 29분께 현장으로 출동했다 성씨는 그사이 부동산 앞에 놓아뒀던 가방을 챙겨 오패산 쪽으로 도망간 후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eibs377TbdcA",
    "outputId": "c363021b-05de-4f80-ae84-ad4f33095b8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='후였다  김 경위는 오패산 터널 입구 오른쪽의 급경사에서 성씨에게 접근하다가 오후 6시 33분께 풀숲에 숨은 성씨가 허공에 난사한 10여발의 총알 중 일부를 왼쪽 어깨 뒷부분에 맞고 쓰러졌다  김 경위는 구급차가 도착했을 때 이미 의식이 없었고 심폐소생술을 하며 병원으로 옮겨졌으나 총알이 폐를 훼손해 오후 7시 40분께 사망했다  김 경위는 외근용 조끼를 입고 있었으나 총알을 막기에는 역부족이었다  머리에 부상을 입은 이씨도 함께 병원으로 이송됐으나 생명에는 지장이 없는 것으로 알려졌다  성씨는 오패산 터널 밑쪽 숲에서 오후 6시 45분께 잡혔다  총격현장 수색하는 경찰들 서울 연합뉴스 이효석 기자 19일 오후 서울 강북구 오패산 터널 인근에서 경찰들이 폭행 용의자가 사제총기를 발사해 경찰관이 사망한 사건을 조사 하고 있다  총 때문에 쫓던 경관들과 민간인들이 몸을 숨겼는데 인근 신발가게 직원 이모씨가 다가가 성씨를 덮쳤고 이어 현장에 있던 다른 상인들과 경찰이 가세해 체포했다  성씨는 경찰에 붙잡힌 직후 나 자살하려고 한 거다 맞아 죽어도 괜찮다 고 말한 것으로 전해졌다  성씨 자신도 경찰이 발사한 공포탄 1발 실탄 3발 중 실탄 1발을 배에 맞았으나 방탄조끼를 입은 상태여서 부상하지는 않았다  경찰은 인근을 수색해 성씨가 만든 사제총 16정과 칼 7개를 압수했다 실제 폭발할지는 알 수 없는 요구르트병에 무언가를 채워두고 심지를 꽂은 사제 폭탄도 발견됐다  일부는 숲에서 발견됐고 일부는 성씨가 소지한 가방 안에 있었다')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNXOrYjPbvmD"
   },
   "source": [
    "## 4-2. SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtPaYTzecQY-",
    "outputId": "dd01095e-5492-4986-b6e2-da453d685428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: langchain-community<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.3.24)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.11 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.11)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.7.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.10.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain_experimental) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_experimental) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.2.2)\n",
      "Downloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain_experimental\n",
      "Successfully installed langchain_experimental-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_experimental tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnhW75o2cJYr"
   },
   "source": [
    "SemanticChunker는 LangChain의 실험적 기능 중 하나로, 텍스트를 의미론적으로 유사한 청크로 분할하는 역할을 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj0JmTQRdNDu"
   },
   "source": [
    "이 방법에서는 지정한 breakpoint_threshold_amount 표준편차보다 큰 차이가 있는 경우 분할됩니다.\n",
    "\n",
    "breakpoint_threshold_type 매개변수를 \"standard_deviation\"으로 설정하여 청크 분할 기준을 표준편차 기반으로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PlIOpMKbfih",
    "outputId": "c7ef7c51-1327-4480-e50f-4c088c3ad7eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-28be2501badb>:6: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  text_splitter = SemanticChunker(OpenAIEmbeddings(),\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI 임베딩을 사용하여 의미론적 청크 분할기를 초기화합니다.\n",
    "\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings(),\n",
    "    breakpoint_threshold_type=\"standard_deviation\",\n",
    "    breakpoint_threshold_amount=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5EGxOnVc8FW"
   },
   "outputs": [],
   "source": [
    "script = '''허수현은 한반도 최북단 탄광마을이 낳은 수재였다. 그는 고등학교 졸업 직전 북한 전체에서 700명에게만 수여하는 ‘7.15 최우등상’을 수상했다. 7.15최우등상은 김정일이 평양 남산고급중학교를 졸업한 날인 1960년 7월 15일을 기념해 1987년에 만들어진 상이다.\n",
    "\n",
    "지금은 이 상이 특권층 자식들을 대학에 보내기 위한 발판이 돼 각종 비리와 뇌물로 얼룩져 있지만, 상이 제정된 초기 몇 년은 정말 공부 잘하는 사람에게만 수여됐다. 상을 받게 되면 곧바로 중앙급 대학에 진학할 수 있었다. 북한에선 고등중학교 졸업생 중 20% 미만이 대학이나 전문학교에 갈 수 있다는 것을 감안하면 엄청난 특혜였다.\n",
    "\n",
    "허 씨도 김책공업종합대학(김책공대)에 입학해 8년이나 공부했다. 그리고 그때 배운 지식을 활용해 지금은 한반도 최남단인 경남 마산의 해저터널 공사장에서 시공품질을 관리하는 공사차장으로 일하고 있다. 김책공대 졸업생이 네 번의 탈북을 반복한 뒤 건강이 악화돼 남의 등에 업혀 동남아 정글을 넘어 한국까지 오게 되고, 이후 남과 북에서 동시에 측량기사 자격을 받은 최초의 기술자가 돼 해저터널 공사장에서 일하게 되기까지 삶의 과정은 결코 순탄하지 않았다.\n",
    "\n",
    "\n",
    "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
    "\n",
    "\n",
    "● 신분 상승의 꿈\n",
    "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
    "\n",
    "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
    "\n",
    "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
    "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
    "\n",
    "아버지가 사망하자 허 씨는 1년 정도 방황했다. 학교에도 나가지 않았다. 하지만 곧 마음을 다잡고, 부친의 소원대로 신분 상승을 하기로 결심했다. 3년을 열심히 공부해 고등학교 졸업반이 됐을 때 허 씨는 7.15 최우등상을 받을 정도로 공부를 잘하게 됐다. 북한도 대도시의 교육 환경이 매우 좋기 때문에 외진 탄광마을에서 수상자를 배출한다는 것은 하늘의 별 따기였다.\n",
    "\n",
    "하지만 상을 받아도 문제였다. 평양에서 대학을 다닌다는 것은 가족들에겐 엄청난 희생이 필요한 일이었다. 그런데 그가 김책공대에 입학한 1992년엔 탄광마을에 배급이 제대로 공급되지 않았다. 평양에서 대학을 다닐 돈이 나올 리 만무했다.\n",
    "\n",
    "허 씨는 대학 대신에 군대에 가려고 시도했다. 대학을 갈 사정이 못되니 군에 입대해 노동당원이 되면 신분이 그나마 좀 바뀔 것이라고 생각했던 것이다.\n",
    "\n",
    "하지만 7.15 최우등상 수상자는 군대에 보내지 않는다는 지침이 있어 결국 갈 수는 없었다. 그는 울며 겨자 먹기로 김책공대 지질탐사학부에 입학했다.\n",
    "\n",
    "그해 온성에서 중앙대학에 입학한 사람은 단 두 명이었다. 허 씨 외에 이과대학 입학생이 한 명 더 있었다. 온성군은 그런 동네였다.\n",
    "\n",
    "● 돈에 성적을 뺏기던 시절\n",
    "북한의 다양한 산업현장에서 활약하는 인재들을 키우는 김책공대는 학제가 길어 7년을 다녀야 졸업증을 받을 수 있다. 그런데 대학을 다니며 각종 공사현장에 끌려 다니다 보니 진도가 밀려 7년 안에 졸업하기가 어렵다. 허 씨도 학제보다 1년을 더 다녀 2000년에야 졸업할 수 있었다.\n",
    "\n",
    "그가 대학을 다니던 1990년대 중반은 북한에서 고난의 행군 시기라 사방에서 아사자가 속출할 때였다. 대학 기숙사에서 주는 밥을 먹으면 굶어죽을 수밖에 없었다.\n",
    "\n",
    "탄광마을에서 태어나 김책공대에 입학한 허 씨와, 어촌마을에서 태어나 김일성대에 입학한 기자는 평양에서 대학을 다닌 시기가 정확히 겹친다. 그래서 인터뷰 내내 떠올리기 싫은 추억들이 소환됐다. 몇 개를 소개하면 이런 식이다.\n",
    "\n",
    "“1993년 공화국 창건 행사 때 김일성대 학생들은 깃발을 들고 김일성광장을 통과했습니다. 그 연습만 3개월 하면서 너무 힘들어 죽을 뻔 했죠.”\n",
    "\n",
    "“김책공대는 촛불을 들고 김일성대를 따라갔죠. 저도 죽을 뻔 했어요.”\n",
    "\n",
    "“제대군인인 학급 소대장, 청년단체비서 이런 사람들은 가난한데 공부 잘하는 학생들을 곁에 한둘씩 끼고 있죠. 그리곤 시험 때마다 자기 것도 좀 써달라고 사정하죠. 그걸 거절하기 어려워 저는 시험 칠 때마다 시험지 3개를 써주었어요. 다양한 볼펜을 준비해서 한 장은 정자로 쓰고, 다른 장은 흘겨 쓰고, 이런 식으로 답을 적어 교수가 뒤돌아서 있을 때 공부 못하는 제대군인들에게 몰래 건네주었죠. 대신 그들은 각종 비용을 걷을 때 나를 빼주기도 했고, 가끔 도시락도 두 개를 갖고 와서 허기진 배도 채워주었습니다.”\n",
    "\n",
    "“저도 그랬어요. 국가졸업시험 때까지 남의 시험지를 작성해주었어요. 대신 저는 돈을 받았습니다. 방학 때 집에 가지도 않았지요. 온성까지 기차로 일주일 넘게 걸리는데 왔다갔다 시간 낭비가 크고, 또 가봐야 집에서 보태줄 수도 없으니 방학 때는 제대군인들 과외를 해주고 돈을 받았습니다.”\n",
    "\n",
    "“저는 졸업장을 받고 나니, 3점짜리 과목이 몇 개 있었어요. 저는 대학 내내 3점을 받은 적이 없거든요. 5점 만점에 3점은 낙제를 겨우 면한 수준인데, 대학 교무부에 찾아가 싸우지도 않았어요. 어차피 이 체제가 싫어서 탈북하려 결심한 마당에 3점이 대수냐고 생각했죠.”\n",
    "\n",
    "“저도 졸업증에 받지 않은 3점들이 있었어요. 권력자 부모를 둔 학생들은 좋은 곳에 가기 위해 대학 교무부 직원들에게 뇌물을 주고 컴퓨터에서 점수를 바꾸었어요. 5점 최우등생과, 4점 우등생, 3점 보통생의 전체 비율을 바꿀 수 없으니 5점으로 조작하려면 누군가의 점수를 빼앗아야 했죠. 제일 힘이 없는 우리가 점수를 빼앗긴 거였죠.”\n",
    "\n",
    "최우등을 하고도, 돈과 권력이 없으면 3점 졸업증을 받아야 했던 시대. 허 씨와 기자는 그 시대에 평양에서 대학을 다녔다. 기숙사에서 밥을 몇 숟가락만 주던 때라 대학 시절을 떠올리면 배고팠던 기억밖에 없다. 졸업증을 받은 것만으로도 기적이었다. 뇌물로 성적을 조작하고, 남의 졸업논문을 베껴 써서 제출하는 상황은 지금도 별반 나아지진 않았다.\n",
    "\n",
    "\n",
    "2018년 뉴질랜드로 한 달 동안 어학연수를 떠났던 시기의 모습.\n",
    "\n",
    "\n",
    "● 북한의 측량기사들\n",
    "아버지가 없는 가난한 탄광마을 출신의 김책공대 졸업생에게 좋은 직업이 기다릴 리 만무했다. 북한은 직업 선택의 자유가 없다. 대학을 졸업하면 중앙에서 어디로 가라고 임명한다.\n",
    "권력과 부를 가진 집안에서 태어나면 대학 때 실컷 놀고도 중앙당이나 외화벌이 업체, 보위부 등 권력기관에 발령을 받는다. 가난한 자들의 운명은 그와 반대이다.\n",
    "\n",
    "허 씨는 2000년 3월 대학을 졸업하면서 졸업증과 함께 측량기사 자격을 부여받았다. 그리고 평양 인근 대동군 시정노동자구에 있는 중앙측량단으로 발령을 받았다. 모두가 기피하는 직업이었다.\n",
    "\n",
    "측량기사는 20㎏이 넘는 장비를 메고 매일 같이 산을 오르내려야 했다. 1000분의 1 오차 범위 내에서 지도에 점 하나를 찍는데 사나흘이 걸렸고, 한 구역을 측량하는데 2~3개월이 걸렸다. 깊은 산속에 천막을 치고 야인생활을 하기 일쑤였다. 그나마 현장기사는 배급을 받을 수 있어 다행이었다.\n",
    "\n",
    "북한은 측량을 하는 기관이 두 개가 있다. 하나는 중앙측량단이고, 다른 하나는 인민무력부(군) 측지국이다. 그런데 진짜 좌표는 측지국이 갖고 있다. 중앙측량단의 좌표는 일부러 정확한 좌표와 다르게 작성한다. 좌표가 고급 비밀이기 때문에 외부에 정보가 새나가면 안된다는 이유 때문이다.\n",
    "\n",
    "허 씨는 한국에 온 뒤 큰 허탈감을 느꼈다. 위성으로 GPS를 찍는 시대를 보니 그 무거운 장비를 메고 다니며 점 하나를 찍겠다고 며칠씩 바친 과거가 너무 허망하게 생각됐기 때문이다. 북한도 2005년경부터 러시아 위성항법체계인 ‘글로나스’의 도움을 받아 위성 측량을 시도했다고는 알려졌지만, 어느 정도 활용되는지는 아직 파악되지 않고 있다.\n",
    "\n",
    "● 원시적 석탄채굴\n",
    "허 씨는 2001년 말에 온성으로 돌아왔다. 뇌물이 없으면 이직도 힘든 세상이지만, 아버지도 없는데 어머니마저 아파서 쓰러졌다고 하니 집으로 보내준 것이다. 실제로 어머니를 간호할 사람은 허 씨 밖에 없었다.\n",
    "\n",
    "새로 발령받은 직장은 풍인탄광 기술과였다. 그러나 할 일은 없었다. 1990년대 중반 고난의 행군 시기 온성 탄광들은 모두 침수됐다. 전기가 없어 물을 빼낼 수가 없었기 때문이다. 그렇게 몇 년을 방치하다보니 갱을 다시 사용할 수가 없었다.\n",
    "\n",
    "탄광에 다니던 사람들은 먹고 살기 위해 다른 방법을 찾았다. 일제 때 했던 방식대로 얇은 탄층 채굴을 시작한 것이다. 삽과 곡괭이로 수직굴을 파들어 가는데, 운이 좋으면 8m에서 탄층을 만나기도 하지만, 운이 나쁘면 25m까지 파들어 간다. 탄층을 만나면, 그걸 따라 이번엔 가로로 파 들어간다. 탄층의 두께는 보통 0.8~1.2m였다. 양동이를 매단 도르래를 타고 수직굴에 들어가 몸을 돌리기도 어려운 좁은 공간에서 석탄을 파서 다시 양동이로 끌어올렸다. 도무지 현대인이라고 볼 수 없는 원시적 채탄방식이었지만, 그렇게 해서라도 석탄을 캐서 팔아야 장마당에서 먹을 것을 사올 수 있었다. 이런 수직굴을 온성에선 ‘노두’라고 불렀다. 온성에는 이런 노두가 수없이 많았다. 노두당 가족, 친척, 친구 등 5~7명이 팀을 이뤄 작업했는데, 이런 사람들을 ‘노두공’이라 불렀다. 북쪽은 날씨가 춥기 때문에 먹는 것 못지않게 석탄도 귀하다. 캐내면 파는 것은 큰 문제가 안됐다.\n",
    "\n",
    "노두도 1년 내내 할 수 있는 것이 아니었다. 땅이 어는 1~3월에만 할 수 있었고, 봄이 와서 땅이 녹으면 수직갱이 버틸 수 없기 때문에 버려야 했다. 구멍을 방치해서도 안됐다. 단속기관 사람들이 찾아와 갱을 다시 메웠는지 조사한다. 단속할 권한이 있다는 것은 뇌물을 받을 수 있다는 것을 의미하기 때문에 얼렁뚱땅 넘어가지 않는다.\n",
    "\n",
    "온성 전체에 이런 노두가 수없이 생겨났다 사라졌다. 겨울이면 할 일이 없는 농민들도 이 일에 매달렸다. 안전은 뒷전이라 붕괴와 추락, 가스질식 등으로 죽는 사람들이 계속 생겨났지만 큰 문제가 되진 않았다. 그 일을 하지 않으면 어차피 굶어죽기 때문이다.\n",
    "\n",
    "허 씨가 소속된 기술과는 늘 각종 공사에 동원됐다. 도로 공사, 발전소 공사 등등 인력을 차출하는 공사는 끊이질 않았다. 김책공대에서 배운 지식을 쓸 곳은 없었다.\n",
    "\n",
    "이렇게 살다가 어느새 결혼할 나이가 됐다. 그래도 허 씨는 명색이 탄광마을이 배출한 수재이고, 평양에서 김책공대까지 나왔던 터라 여성들에게 나름 인기가 있었다.\n",
    "\n",
    "32살 때인 2006년 그는 10살 어린 여성과 결혼했다. 아내는 탄광 선전대 가수로 나름 인기가 좋았다. 이성적인 지식인과 감성적인 예술인의 조합이었다.\n",
    "\n",
    "그렇지만 매력과 결혼생활은 별개였다. 결혼한 직후부터 둘은 다투는 일이 많았다. 서로가 서로를 견디기 어려워했다. 4년간의 결혼생활 끝에 둘은 이혼하기로 합의했다. 어린 딸은 아내가 키우기로 했다. 이때부터 그는 중국으로 눈을 돌렸다.\n",
    "\n",
    "\n",
    "2022년 인천지하철 공사 현장에서 일하고 있는 허 씨.\n",
    "\n",
    "\n",
    "● 두만강을 넘나들다\n",
    "강 건너 연변 왕청에는 아버지의 삼촌과 사촌 등 친척들이 살고 있었다. 국경 근처라 많은 사람들이 중국을 드나들 때도 허 씨는 명색이 김책공대 졸업생인데 조국을 배반하면 안 된다는 마음이 컸다. 하지만 이혼 후 세상이 달리 보이기 시작했다. 이혼까지 한 마당에 눈치 볼 일도, 무서울 일도 없었다.\n",
    "\n",
    "2010년 겨울 그는 국경경비대에 돈을 쥐어주고 두만강을 넘었다. 탈북한 것은 아니고, 친척에게 도움만 받자는 목적이었다. 저녁에 넘어가서 친척에게 전화를 하고 새벽이 되기 전에 다시 북으로 넘어왔다.\n",
    "\n",
    "2012년 2월 그는 두 번째로 중국으로 갔다. 당시는 김정일이 사망한지 얼마 안됐던 때라 경계가 매우 심했다. 그는 북한군 군복을 입고 길을 떠났다. 군인은 초소에서 잘 단속하지 않았기 때문이다. 강을 따라 난 도로로 한참을 가다가 어둠이 내릴 때 바로 두만강을 넘었다. 중국 부락의 아무 집이나 들어가 왕청 친척에게 전화를 좀 하고 싶다고 했다. 전화를 하고 몇 시간 정도 머물렀는데 갑자기 공안이 들이닥쳤다. 집주인이 그를 도와주는 척하고는 신고를 했던 것이다. 알고 보니 중국은 그즈음부터 탈북자를 신고하면 포상금을 주는 제도를 운영하고 있었다. 특히 북한군 국경경비대가 수시로 건너와 사람까지 죽이며 노략질을 했기 때문에, 중국에서 북한군은 최고의 기피대상이었다.\n",
    "\n",
    "탈북자들이 북송 전 대기하는 도문변방수용소에 끌려갔는데 며칠 뒤 보위부에서 차를 갖고 건너와 그를 싣고 갔다.\n",
    "\n",
    "그렇지만 그는 예상과는 달리 20일 정도 가수감됐다가 석방됐다. 서류를 보니 중국에 친척이 다 있는 것도 확실하니, 도움 좀 받으려 넘어갔을 뿐이라는 그의 말이 인정됐다. 탈북은 배반이지만, 그의 경우엔 일탈 정도로 간주됐다.\n",
    "\n",
    "보위부라고 해봐야 어차피 한동네 사는 아는 사람들이었는데, 그들은 지역이 배출한 인재의 경력을 망가뜨리고 싶지 않았는지 그다지 혹독하게 대하진 않았다.\n",
    "\n",
    "하지만 허 씨 입장에선 아무 것도 이루지 못하고 잡혀오니 화가 났다. 보위부 감방에서 그는 강 건너편에서 일하다 잡혀왔다는 사람을 알게 됐다. 그는 자기가 일했던 중국 훈춘의 한 슈퍼의 이름을 알려주면서, 다시 건너가 자기 이름을 대면 사장이 고용해 줄 것이라고 했다.\n",
    "\n",
    "감방에서 나온 허 씨는 다시 두만강을 넘었다. 세 번째 탈북이었다. 그는 감옥 동기가 알려준 슈퍼로 갔다. 왕청에 가지 않은 이유는 친척들은 별로 도와줄 의향이 없어 보였기 때문이다.\n",
    "슈퍼는 중국과 나진선봉을 연결하는 도로 옆에 있었는데, 두만강 건너 허 씨네 동네가 약 10㎞ 밖에 빤히 바로 보였다. 허 씨가 내륙 깊이 들어가지 않은 이유는 딸을 데려오고 싶어서였다. 고향 가까이 있어야 집과 연락이 수월하다고 판단했다. 허 씨가 일하는 슈퍼에는 북한을 오가는 운전기사들이 수시로 드나들었다. 이들을 통해 그는 전처에게 휴대전화를 전달할 수 있었다.\n",
    "\n",
    "● 자수해 감옥에 가다\n",
    "그렇게 1년쯤 지났는데 사고가 생겼다. 중국 휴대전화를 받은 전처가 그걸 이용해 돈 벌려고 브로커 일을 하다가 보위부에 체포된 것이다. 전 남편마저 실종되니 보위부는 그녀에게 한국행을 기도했다는 누명을 씌웠다.\n",
    "\n",
    "그 소식이 허 씨에게도 전달됐다. 그래도 4년 간 살았던 정도 있고, 어린 딸까지 있으니 모르는 척 할 수가 없었다. 그는 다시 북에 나가기 위해 자수하기로 결심했다. 자신이 나타나야 전 남편이 한국에 갔다는 누명을 벗길 수 있을 것 같았다.\n",
    "\n",
    "슈퍼 주인은 전과자 출신이었는데, 그가 북으로 가겠다고 하자 감옥에서 나오는 자기의 비법을 전수해주었다. 폐 주변에 황산철을 주사하면 고열이 나고, 염증이 생긴다면서, 자신은 그 방법으로 병원에 호송됐다가 도망쳤다고 했다. 단 이 방법의 단점은 한 달 안에 황산철을 세척하지 못하면 생명을 잃을 수도 있다고 했다.\n",
    "\n",
    "허 씨는 그의 조언에 따라 폐에 황산철을 네 군데나 주입했다. 그리고 스스로 공안에 자수한 뒤 2014년 4월 13일 북송됐다. 그런데 이번은 보위부도 호락호락하지 않았다. 불행하게도 그가 자수한 뒤 공안이 그의 숙소를 뒤져 소지품을 북송할 때 함께 보냈던 것이다. 그 속에는 한국 영사관, 한국인 전도사 등의 전화번호가 적힌 수첩이 있었다. 이게 화근이 됐다. 고문이 시작됐다.\n",
    "\n",
    "중국 사장이 알려준 방법은 확실히 효과가 있었다. 폐가 곪아가기 시작했던 것이다. 염증으로 심한 열까지 나 거동을 못할 정도가 됐다. 보위부는 감방에서 죽이긴 싫었는지 그를 가석방으로 집에 보냈다.\n",
    "\n",
    "그때가 5월 말이었다. 중국 사장이 당부한 폐를 씻어야 하는 한 달이 지난 것이다. 집에 가서 이러저런 치료를 해봤지만 점점 악화됐다. 이렇게 지내다간 죽을 것 같았다. 그는 황산철 주사를 맞은 지 네 달이 지난 8월 23일 다시 중국으로 넘어왔다. 이번엔 하얼빈에 들어가 식당에 취직해 치료에만 전념했다. 하지만 몸은 점점 더 쇠약해졌다.\n",
    "\n",
    "몸을 운신하기 어려워지자 허 씨는 죽더라도 고향에 가서 죽겠다고 생각했다. 그해 11월말 그는 다시 연길에 왔다. 연길에서 혹시나 도움을 받지 않을까 싶어 처음으로 교회에 찾아갔는데, 거기서 집도 제공하고 치료도 해주었다. 12월 말 허 씨는 산소 호흡기에 의지하는 신세가 됐다. 쇼크도 수시로 왔다. 교회에선 한국에 가서 치료를 받아야 살 수 있다며 한국행선을 주선해주었다.\n",
    "\n",
    "\n",
    "교회 목회자가 될 꿈을 꾸던 당시의 허 씨. 2017년 뉴욕에서 찍은 사진이다.\n",
    "\n",
    "\n",
    "● 최초로 남북 측량기사 자격 모두 획득\n",
    "2015년 2월 그는 여러 탈북민들과 함께 한국으로 떠났다. 동남아 정글에서 일행을 따라갈 수 없을 때 친한 동생이 그를 업고 산을 넘었다. 우여곡절 끝에 한국에 도착했지만 다음날 적십자병원에 실려갔다. 이곳에서 4개월 동안 치료를 받다보니 하나원도 나오지 못했다.\n",
    "\n",
    "허 씨는 인천에 거주지가 배정됐다. 건강이 너무 악화돼 일을 할 수 없는 상태라 2016년말까지 병원에 다니며 통원치료를 받았다. 하나원을 나온 다른 사람들이 하나둘 취직해 일자리를 얻는 것을 보고 조급한 마음에 노량진에서 공무원 시험을 준비하기도 했지만, 건강이 악화돼 다시 병원에 실려 가기도 했다. 한국의 의술은 역시 대단했다. 2년이라는 오랜 시간이 걸리긴 했지만, 끝내 허 씨를 완치시켰다.\n",
    "\n",
    "치료 받는 기간에 허 씨는 목회자의 길을 걸어볼까 싶어 1년 남짓 성경공부도 했고, 화장품 회사에 취직해 일도 해봤지만 적성에 맞지 않았다.\n",
    "\n",
    "많은 고민 끝에 북에서 배운 측량기사 일을 다시 해보려 알아보니, 남쪽도 측량기사는 일도 힘들고 보상도 적었다. 그렇지만 적성에 맞지 않는 곳에서 시간을 낭비하는 것보다는 그래도 자신있는 분야를 파보자는 생각에 2018년 한 엔지니어링 회사에 취직했다. 취직은 했어도 아무런 건설기술인 등급도 받지 못했기 때문에 회사에서 가장 많은 나이임에도 허드레 일만 해야 했다. 연봉은 2300만 원이었다. 그는 앞으로 살아가려면 자격증이 필수라는 것을 깨달았다. 어떤 자격을 갖고 있고, 어떤 경력을 쌓는가에 따라 연봉도 결정됐다.\n",
    "\n",
    "허 씨는 회사에 다니며 1년 동안은 토목계측에 대한 용어부터 수첩에 적어 기본적인 지식을 배웠다. 그리고 이듬해 대구과학대에 입학했다. 일도 하면서 대학 공부까지 하려니 야간반을 다닐 수밖에 없었는데, 전국의 측량 관련 야간반 중에 대구가 그나마 가까웠다.\n",
    "\n",
    "가깝다고 해도 당시 일을 하던 포항의 건설현장에서 150㎞나 떨어져 있었다. 일주일에 서너번씩 왕복 300㎞를 달려 수업을 듣고 오는 일은 결코 쉽지 않았다.\n",
    "\n",
    "돌아오는 길에 너무 피곤해 졸음 쉼터에서 쪽잠을 자기 일쑤였다. 잠깐 눈을 붙인다는 것이 해가 중천에 걸릴 때까지 잔적도 있다.\n",
    "\n",
    "허 씨는 대학 공부와 병행해 자격증 시험도 준비했다. 3년 동안 주경야독의 삶을 끈질기게 이어나간 끝에 그는 2022년 대학을 우수한 성적으로 졸업하고, 동시에 측량 및 지형공간정보기사와 토목기사 자격증을 받을 수 있었다. 허 씨는 남과 북에서 측량기사 자격을 각각 받은 최초의 사례다.\n",
    "\n",
    "이러한 자격증과 경력을 인정받아 현재 허 씨는 건설기술인협회에서 고급기술인으로 인정받고 있으며, 300억 원 규모 이상의 토목공사를 책임지고 할 수 있다.\n",
    "\n",
    "\n",
    "2019년 여수에서 전력 케이블용 해저터널 공사장에서 작업하는 모습. 뒷모습이 보이는 사람이 허 씨이다.\n",
    "\n",
    "\n",
    "● “배워야 살 수 있다”\n",
    "허 씨는 김책공대에서 무려 8년이나 공부를 했지만 여기선 모든 것을 다시 배워야 했다고 말했다.\n",
    "\n",
    "“남쪽에 오니 용어는 물론, 장비나 자재 등 모든 것이 북한과 달랐습니다. 비유하면 북에서 통나무로 집을 짓는 법을 배웠는데, 남쪽에 오니 시멘트로 아파트를 짓는 격이죠. 그럼 집 짓는 법을 처음부터 다시 배워야하죠. 물론 북한 김책공대 과정이 전혀 의미 없는 것은 아닙니다. 북한에선 가장 기본적인 것, 즉 공부하는 방법을 배운 것 같습니다.”\n",
    "\n",
    "그는 남북은 통합성에서도 차이가 크다고 했다.\n",
    "\n",
    "“여기는 한 가지를 하려면 열 가지를 알아야 합니다. 많은 것들이 서로 연결돼 있어 전체적으로 진행되죠. 반면 북한은 직무가 매우 세분화돼 있고, 맡겨진 것만 하면 됐어요.”\n",
    "\n",
    "자격증과 경력을 쌓고 나니 연봉도 빠르게 올라갔다. 김책공대까지 입학했던 북한 시골 수재가 다시 자신의 두뇌와 재능을 발휘하는 데는 오랜 시간이 걸리지 않았다. 2300만 원에서 시작했던 연봉은 6년 만에 3배 이상 높아졌다.\n",
    "\n",
    "그는 여기에 만족하지 않았다. 그는 올해 3월 다시 대구대 공간정보전문기술 석사과정에 입학했다. 토질 및 기초기술사 자격을 취득하기 위해서다. 다른 자격증과는 달리 이 자격은 받기가 매우 어렵다. 허 씨의 계획은 향후 5년 안에 석사와 함께 기술사 자격을 획득하는 것이다.\n",
    "\n",
    "그렇다고 공부만 할 수는 없는 일. 요즘 허 씨는 마산만에서 스팀배관 부설을 위한 해저터널을 뚫는 작업을 하고 있다. 그의 직책은 공사차장. 터널 시공 품질을 총괄하는 중요한 자리다.\n",
    "\n",
    "건설 현장은 매우 거칠고 다툼도 많다. 외국인 근로자들도 많아 의사소통의 문제도 많다. 많은 어려움이 있지만 허 씨는 포기하지 않고 한 걸음씩 나가고 있다.\n",
    "\n",
    "“거친 현장이라서 그런지 북에서 왔다고 우습게 보는 사람들이 많아요. 아직도 저는 ‘나는 여전히 이방인이구나’라는 생각을 하고 있습니다. 그렇지만 실력은 남에게 뒤진다고 생각하지 않습니다. 여러 곳에서 이직 제안도 많이 받습니다.”\n",
    "\n",
    "2023년 남북하나재단이 주관한 정착사례 발표대회에서 그는 최우수상인 통일부 장관상을 받았다. 하지만 허 씨는 지금은 정착의 첫 발자국을 뗀 것에 불과하다고 했다.\n",
    "\n",
    "그는 자신의 이름으로 회사를 만들어 키우는 것을 다음 목표로 정했다. 그 목표가 달성되면 또 할 일이 있다. 나아가 통일이 되면 할 계획도 미리 생각해두었다.\n",
    "\n",
    "“저는 북에 돌아가 여기서 배운 기술을 북에 전수할 겁니다. 한국은 토목 공사를 할 때 측량, 시공, 품질까지 다 알아야 합니다. 통일 되면 교통인프라를 다시 정리해야 할 것인데, 북한에서 대학을 다녔던 동창들은 통합성에 있어 크게 떨어집니다. 이런 것을 가르쳐야죠. 그리고 남북에서 모두 측량기사 자격을 받은 유일한 사람이니 다른 꿈도 있습니다. 남북공간정보 통합지도체계를 만드는 것도 중요한 목표입니다.”\n",
    "\n",
    "꿈을 말할 때 그는 가장 행복한 표정이었다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm_05l9pcd_0"
   },
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text(script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ll17ctMFckz5",
    "outputId": "036db03d-00bc-40bd-fa85-96c15d7c5729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "bPIr7nd4clJy",
    "outputId": "c7843cc6-d06c-425f-c39c-9b8197e65178"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'허수현은 한반도 최북단 탄광마을이 낳은 수재였다. 그는 고등학교 졸업 직전 북한 전체에서 700명에게만 수여하는 ‘7.15 최우등상’을 수상했다. 7.15최우등상은 김정일이 평양 남산고급중학교를 졸업한 날인 1960년 7월 15일을 기념해 1987년에 만들어진 상이다. 지금은 이 상이 특권층 자식들을 대학에 보내기 위한 발판이 돼 각종 비리와 뇌물로 얼룩져 있지만, 상이 제정된 초기 몇 년은 정말 공부 잘하는 사람에게만 수여됐다. 상을 받게 되면 곧바로 중앙급 대학에 진학할 수 있었다. 북한에선 고등중학교 졸업생 중 20% 미만이 대학이나 전문학교에 갈 수 있다는 것을 감안하면 엄청난 특혜였다. 허 씨도 김책공업종합대학(김책공대)에 입학해 8년이나 공부했다. 그리고 그때 배운 지식을 활용해 지금은 한반도 최남단인 경남 마산의 해저터널 공사장에서 시공품질을 관리하는 공사차장으로 일하고 있다. 김책공대 졸업생이 네 번의 탈북을 반복한 뒤 건강이 악화돼 남의 등에 업혀 동남아 정글을 넘어 한국까지 오게 되고, 이후 남과 북에서 동시에 측량기사 자격을 받은 최초의 기술자가 돼 해저터널 공사장에서 일하게 되기까지 삶의 과정은 결코 순탄하지 않았다. 2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Cc0O1qx4dIHp",
    "outputId": "7f86563a-f268-4edd-86e2-bfbf06a9bf61"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'● 신분 상승의 꿈\\n그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "TAtZD1hIdJ8J",
    "outputId": "d910f840-e13b-4388-93e2-27ddf36f177c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다. 온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다. 탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다. 부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다. 아버지가 사망하자 허 씨는 1년 정도 방황했다. 학교에도 나가지 않았다.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "id": "DTifldRwfF0B",
    "outputId": "ebbe9295-78f0-41a4-b2a4-a415b71d87d8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'하지만 곧 마음을 다잡고, 부친의 소원대로 신분 상승을 하기로 결심했다. 3년을 열심히 공부해 고등학교 졸업반이 됐을 때 허 씨는 7.15 최우등상을 받을 정도로 공부를 잘하게 됐다. 북한도 대도시의 교육 환경이 매우 좋기 때문에 외진 탄광마을에서 수상자를 배출한다는 것은 하늘의 별 따기였다. 하지만 상을 받아도 문제였다. 평양에서 대학을 다닌다는 것은 가족들에겐 엄청난 희생이 필요한 일이었다. 그런데 그가 김책공대에 입학한 1992년엔 탄광마을에 배급이 제대로 공급되지 않았다. 평양에서 대학을 다닐 돈이 나올 리 만무했다. 허 씨는 대학 대신에 군대에 가려고 시도했다. 대학을 갈 사정이 못되니 군에 입대해 노동당원이 되면 신분이 그나마 좀 바뀔 것이라고 생각했던 것이다. 하지만 7.15 최우등상 수상자는 군대에 보내지 않는다는 지침이 있어 결국 갈 수는 없었다. 그는 울며 겨자 먹기로 김책공대 지질탐사학부에 입학했다. 그해 온성에서 중앙대학에 입학한 사람은 단 두 명이었다. 허 씨 외에 이과대학 입학생이 한 명 더 있었다.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQr7HWHhfUSu"
   },
   "source": [
    "# 5. Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHp04CBdfiVq"
   },
   "source": [
    "## 5-1. OpenAI Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "rPCHN1HTf6bu",
    "outputId": "78987e0d-351b-466a-fe1f-1a85ea907c99"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\\uc800\\ub294 \\ubc30\\uac00 \\uace0\\ud30c\\uc694\",\n          \"\\uc800\\uae30 \\ubc30\\uac00 \\uc9c0\\ub098\\uac00\\ub124\\uc694\",\n          \"\\uc2a4\\ud300\\uc5d0\\uc5b4\\ud504\\ub77c\\uc774\\uc5b4\\ub85c \\uc5f0\\uc5b4\\uad6c\\uc774 \\ud574\\uba39\\uc744\\uac70\\uc57c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-1a5fb1be-e5b9-4f76-bf25-e1db5aa10c0d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 배가 고파요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저기 배가 지나가네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>굶어서 허기가 지네요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>허기 워기라는 게임이 있는데 즐거워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스팀에서 재밌는 거 해야지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>스팀에어프라이어로 연어구이 해먹을거야</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a5fb1be-e5b9-4f76-bf25-e1db5aa10c0d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-1a5fb1be-e5b9-4f76-bf25-e1db5aa10c0d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-1a5fb1be-e5b9-4f76-bf25-e1db5aa10c0d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9519898b-0898-4ae0-88af-3ece058e73c7\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9519898b-0898-4ae0-88af-3ece058e73c7')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9519898b-0898-4ae0-88af-3ece058e73c7 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_7f3c0131-2524-4527-a801-c4f5b6f18c92\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_7f3c0131-2524-4527-a801-c4f5b6f18c92 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   text\n",
       "0             저는 배가 고파요\n",
       "1           저기 배가 지나가네요\n",
       "2           굶어서 허기가 지네요\n",
       "3   허기 워기라는 게임이 있는데 즐거워\n",
       "4        스팀에서 재밌는 거 해야지\n",
       "5  스팀에어프라이어로 연어구이 해먹을거야"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "data = ['저는 배가 고파요',\n",
    "        '저기 배가 지나가네요',\n",
    "        '굶어서 허기가 지네요',\n",
    "        '허기 워기라는 게임이 있는데 즐거워',\n",
    "        '스팀에서 재밌는 거 해야지',\n",
    "        '스팀에어프라이어로 연어구이 해먹을거야']\n",
    "\n",
    "df = pd.DataFrame(data, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laxvVgOAfz6u"
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfpEF-IJf042"
   },
   "outputs": [],
   "source": [
    "query_result = embeddings.embed_query('안녕하세요')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pz2E7WcWg65C",
    "outputId": "2ee7eb43-f3fc-4edf-fe55-dd2c783c68dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvSVTsF9g7sB",
    "outputId": "3e956776-4a8d-4ea9-8c8b-f412a089e0c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01363905893128265, -0.009446358031268955, -0.005943919478104129, -0.02294480773314062, -0.012475839748973755, 0.018202455112672995, -0.019774717717347474, 0.005880006530671005, -0.01290405817315644, 0.008788053555120605, 0.012060404659335807, -0.0032292101440946344, -0.02400576489570482, -0.014495493917002743, -0.005608375572757586, -0.00717105160784615, 0.027226986387031634, -0.013421754351216444, 0.007886878761139214, -0.017435497880830222, -0.004291765689138248, -0.015876016748055204, 0.0029112423924244645, -0.012469449013024025, 1.494218680647895e-05, 0.00395302595015552, 0.00401374352961378, -0.023916287141827502, 0.014201493986281313, -0.02166654505918757, 0.002701926930787398, 0.006953747027779942, -0.01880323830866059, -0.005582810766313392, 0.010194142123939902, -0.012322448116340673, 0.0024031330167810336, -0.014802277182268907, 0.005307983974763789, -0.007439486732123384, 0.018125758830695136, -0.014738364234835783, 0.009280183995413775, -0.014252624530492341, -0.0010545664266144725, 0.016694105455431645, -0.0015530886505953408, -0.03144525209348952, 0.006985703501496504, 0.0498777960520961, 0.012635623048879205, 0.012054012992063438, -0.014674451287402657, -0.021040197056755784, 0.00299912292797567, -0.0016233931488855036, -0.012610057311112371, 0.02807063990085227, -0.012680361925817864, -0.036839517522833126, -0.004719983647659613, 0.017269323844975044, -0.006813137798368957, 0.022932026261241162, 0.0030422643537575574, 0.0016521540217965416, -0.002083567581123431, -0.0019221869464765382, -0.03175203349611041, 0.012852927628945411, 0.00023388205028318883, 0.033158122064929706, -0.013677406140948941, -0.01650236661313227, 0.015390277975034403, 0.006445637419305852, -0.009887358858673737, 0.008283139780282698, -0.03351603680572954, 0.001858273766212754, 0.03433412551310598, -0.03530560305914758, 0.007068790519424094, 0.01179836120233094, 0.019263412275237198, 0.028990987834005486, -0.024644896232681346, 0.00296876413824654, -0.019404021504648185, -0.023366635421373575, 0.011900622290752994, 0.020247675018468816, -0.015773757522278428, 0.021768806147609628, -0.02162819878084392, 0.0014428385601594753, 0.0053846797910803304, 0.027559334458741994, -0.006381724471872728, -0.013881928317793052, 0.0035791343694813664, -0.010475359651439232, -0.015786538994177885, 0.0027003290139693058, -0.028198465795718518, 0.0010106261588388695, -0.0013781265379019748, -0.0131916664366055, 0.01651514808503173, -0.0137668848261489, 0.019199499327804074, 0.023954635282816432, -0.01756332377569647, -0.04583848585339285, -0.004381243908676885, 0.03303029617006346, 0.007899661164361312, -0.011402099251864818, -0.007241355756890323, -0.01780619409352951, 0.006132463418089958, 0.0330814295082424, 0.017448279352729683, -0.009663662611335161, 0.002179437235103778, -0.015045147500101948, -0.01233523145088541, -0.02876090085071718, -0.0019829044095194684, 0.0031029817003851577, 0.06150998228724922, 0.015415842781478598, 0.018125758830695136, -0.0010106261588388695, -0.017320453457863434, 0.004895744718762024, -0.0015155397008461164, 0.02277863369728544, -0.03681395457903421, -0.007842138952877916, 0.008059443532944122, 0.01839419395497237, -0.014239842127270244, -0.02541185346452412, 0.0035375908605175714, 0.001003435882403445, 0.03504995126941508, -0.011651361236970225, 0.010232489333606192, -0.0045410267429210165, -0.00452824433969892, -0.003806025984794806, 0.030090295000203895, -0.005234483992083433, 0.008922271117259222, 0.02212672088840946, 0.004122395819646883, 0.01671967026187584, -0.017818975565428972, -0.009484706172257884, -0.0035088299876065336, -0.01438045042535859, 0.028172900989274323, -0.030908381844935055, -0.0031668948806489417, 0.03768317289929904, 0.002671568141058268, 0.0004545820144129303, 4.64618383729712e-05, -0.005979071785456876, -0.003972200020649986, -0.006442442051330987, -0.016310625908187618, -0.009555010786963377, -0.023162113244529464, -0.0013733330202783584, 0.002486220267539283, 0.0022353612969384217, -0.017013670192597266, -0.02323880766386205, -0.032212211187977575, 0.002660383421823603, 0.006615007288797215, 0.016412886996609675, 0.01633619257727709, 0.015045147500101948, 0.016770801737409507, 0.009350488610119268, 0.015262452080168154, -0.004048895836966527, 0.01003435882403445, 0.020707848985045425, 0.02720142158058744, -0.013306710859572291, -0.6409718242265591, -0.0212191544271557, 0.029681250646515674, 0.010878012337855084, 0.003914678274827909, 0.007669573715411688, -0.0015427027733543922, 0.027789421442030296, -0.009222662715253018, 0.04059760926271441, 0.011363752042198525, -0.007644008443306174, -0.017831758899973706, 0.011203968742293076, 0.010833272529593785, -0.014738364234835783, -0.0005244869752909051, -0.0008500444243933575, 0.0041383740565051645, 0.010398663369461372, -0.008979792397419977, 0.003352242754167927, -0.020490545336301857, -0.0073691821174178915, 0.018279151394650858, 0.013856363511348857, -0.0037293301684782646, 0.017320453457863434, -0.019646891822481225, 0.05000562194696235, -0.014303755074703368, 0.026664551332032972, 0.007081572922646192, -0.0030630361082394546, 0.05501640969170721, -0.0029559815021937834, 0.013651841334504748, 0.03625151766139027, 0.02224176344873097, 0.06053850101591706, -0.0035631561326230853, -0.021270284040044087, 0.012757057276473086, -0.035944736258769386, 0.016949757245164142, 0.0027115139660346304, -0.020247675018468816, 0.007759051934950326, -0.009408010821602662, -0.007969965779066805, -0.010846055864138521, -0.010705446634727537, 0.03586803997679153, 0.01179836120233094, -0.0029559815021937834, 0.0031876666351308394, 0.014278189336936534, -0.012143491677263396, 0.011568273287719996, 0.02077176193247855, 0.013587928387071622, 0.016566279560565396, -0.012194622221474423, -0.012974361856539293, -0.03392508115941776, 0.036839517522833126, -0.0217943728166991, -0.0016601431402256822, -0.030039163524670228, -0.01738436640529656, -0.005327158045258255, -0.016246712960754493, -0.011120881724365485, 0.014661668884180561, 0.009593358927952308, 0.01982584733023586, 0.0222801115897199, -0.01110170765387102, -0.011504360340286872, 0.0055444626253244615, 0.0037708736774420596, -0.0019381651833348195, -0.012763448943745455, 0.0012151481028523196, 0.007362790915806843, -0.008634661922487522, -0.03379725526455151, -0.02060558789662337, 0.0017528171934005046, -0.013076622944961348, 0.0421826570645789, 0.0172821053168745, 0.015530887204445388, -0.019404021504648185, -0.0013741319786874046, 0.013306710859572291, -0.014508277251547479, 0.012175448150979958, 0.007976356515016533, 0.0018247193756780996, 0.005736201933285155, 0.0037453084053365457, 0.01445714670733645, -0.007778226005444791, 0.016412886996609675, 0.0062059634007703155, -0.03200768901113347, -0.00876248781735377, 0.012558926766901344, -0.011894230623480627, 0.024274200019982057, -0.0056435278801103324, -0.011964535238186118, 0.006557485542975139, 0.013357841403783318, -0.02162819878084392, -0.005915158838023751, 0.015045147500101948, 0.01278262301423992, -0.005212114553614103, 0.02640889954230047, -0.017729497811551653, 0.027226986387031634, 0.02101463225031159, 0.00407446110907204, 0.01700088872069781, -0.018010716270373622, -0.009529445049196544, -0.01813854216523987, -0.010360316159795081, 0.0009794685271160234, -0.015671496433856374, -0.006940964158896526, -0.036839517522833126, 0.013293927525027555, -0.003706960730008935, 0.0341040366671724, -0.01871376055478327, 0.027457073370319936, 0.005419832098433077, -0.015185755798190294, 0.00998961994709579, 0.0004302151508171531, 0.016003844505566734, 0.008756097081404042, 0.0025181767412558453, -0.016936975773264685, -0.006052571768137232, 0.01703923686168674, 0.01261644897838474, -0.010194142123939902, 0.02187106723603168, -0.0040233305648610124, 0.0029144379932299885, 0.016566279560565396, 0.011977317641408216, 0.008685792466698549, -0.014533842057991672, -0.023047068821562676, -0.009919315332390299, 0.017230975703986115, 0.009433575628046857, -0.010986664162226868, -0.0035951126063396475, 0.02008150098261364, -0.06104980832067262, -0.026050984801500643, 0.007017659975213067, -0.010053532894528917, -0.017601671916685404, -0.010015184753539986, -0.006755616052546881, -0.00407446110907204, -0.0003285533685133801, 0.010219706930384095, -0.011542708481275803, 0.011319012233937227, -0.0016353768265292144, -0.004691222541917915, -0.02699689940374333, 0.006423267980836522, -0.020707848985045425, -0.01651514808503173, 0.01229049164262411, 0.030703859668090947, 0.02486220174407019, -0.0037804607126892924, 0.021653763587288113, -0.01811297735879568, 0.00889031464354266, 0.005921550039634799, 0.010871620670582716, -0.020822893408012216, -0.008781661887848236, -0.0047998748319510185, -0.031164035497312833, 0.003949830582180656, 0.01765280152957379, 0.01261644897838474, 0.021142458145177838, 0.027226986387031634, 0.012795405417462017, 0.025756984870779213, -0.01848367357149497, -0.009235445118475115, -0.008506835096298633, 0.012098752800324736, -0.02568028858880135, 0.026613421719144582, -0.0025069920220211804, 0.005160984009403075, 0.001163218716647576, 0.0015738604050772383, 0.014444364304114353, -0.00917792290699172, 0.02725255119347583, -0.017946803322940498, 0.011088925250648923, -0.02015819540194622, 0.0068514859393578875, 0.00020891599698445962, 0.011958143570913751, -0.026306638453878418, -0.007484225609062043, 0.0010377892313471453, 0.011517143674831608, 0.029885772823359785, 0.037759869181276905, 0.005426223300044126, -0.010513707792428164, -0.036123691766524024, 0.005298397405177876, 0.0032324057449001583, 0.014137581038848188, -0.0066469637625137775, -0.008142530550871713, 0.013779667229370997, -0.01999202136609104, 0.010903577144299278, -0.011018620635943431, 0.0036558301857979075, 0.006295441620308953, 0.012590883240617906, -0.010347532825250345, 0.009842619981735077, 0.03407847372337348, 0.013856363511348857, 0.012757057276473086, -0.002965568537441016, 0.03200768901113347, -0.025731420064335018, 0.009804271840746146, 0.010660707757788877, -0.013920276458781982, -0.012520579557235054, -0.041799175654689595, -0.006231528672875829, 0.003371416824662392, 0.03336264424177382, 0.025015592445380635, 0.01790845518195157, -0.0021602631646093127, 0.01789567184740683, -0.013114971085950278, 0.017831758899973706, 0.018828803115104785, 0.023673416823994462, -0.03960056504758333, -0.008442922148865509, 0.003585525803923075, -0.013345058069238582, -0.02541185346452412, 0.008078617603438589, -0.02456820181334876, 0.0033746124254679165, -0.01512184285075717, 0.018010716270373622, -0.03251899259059846, 0.005036353482511691, 0.005911963004387567, -0.011357360374926158, -0.03604699548454616, -0.0007066393644196956, 0.027840552917563963, 0.009932097735612396, -0.03198212234204399, -0.023788461246961254, 0.0005744191400960285, -0.015466973325689625, 0.021129674810633103, -0.004294961522774431, 0.015773757522278428, 0.0076951389875172015, -0.01048814205466133, -0.014942886411679892, -0.025629158975912964, 0.020055936176169444, -0.004870179446656511, 0.019544630734059168, 0.022586894854986068, 0.010002402350317888, -0.008992574800642075, 0.004413200382393448, -0.010564837405316552, -0.017154279422008253, 0.025782549677223408, -0.002979948857481205, -0.018611499466361217, 0.016783583209308964, -0.008858357238503457, -0.01941680483919292, 0.01848367357149497, -0.029962467242692366, -0.020209326877479887, -0.0131916664366055, 9.142570976452042e-05, -0.03326038501599704, -0.014610538339969533, 0.022292894924264638, -0.0038156130200420386, 0.004004156494366548, -0.005761767205390669, -0.019314543750770866, -0.010334750422028248, 0.04591518213537071, -0.01893106420352684, 0.006209159234406499, -0.007196616879951663, -0.009797880173473779, 0.018994977150959963, -0.02651116063072253, -0.028454119448096293, -0.011312621497987499, -0.017422714546285488, -0.0027115139660346304, -0.017844542234518444, -0.008749705414131673, 0.010986664162226868, 0.03162420760124416, -0.0006487181393930966, 0.021193589620711505, -0.002634818149718089, -0.004911722955620306, 0.018304716201095052, -0.004307743925996529, -0.00909483588906413, 0.0006698893148718521, 0.020758980460579092, 0.027968378812430212, 0.02129584884648828, -0.009350488610119268, -0.001757610594608791, 0.01199649171190268, -0.0159654963645778, -0.013549580246082693, -0.006011028259173438, -0.00869218320264828, -0.010053532894528917, 0.0005348728525318539, 0.06877051025198873, -0.008142530550871713, 0.01859871613181648, -0.0028521227297842963, 0.01593993155813361, 0.03763204328641065, 0.019966456559646847, 0.013818015370359926, -0.0029959273271701462, -0.00790605190031104, -0.002367980942258947, -0.00741392146001787, 0.016975323914253614, 0.0006363349243371978, -0.007669573715411688, 0.026766812420455026, 0.0036654172210451403, -0.026153245889922697, -0.003898700037969628, 0.014265406933714439, -0.00790605190031104, 0.0052408751936944805, -0.004822244270420348, -0.0011656154754593842, 0.004045700003330342, 0.010264445807322754, -0.02876090085071718, -0.0159654963645778, -0.0034960473515537765, -0.015594800151878512, -0.015530887204445388, -0.017435497880830222, -0.010711838301999906, -0.018240803253661928, 0.00026923399537478305, -0.024197505600649472, -0.0172821053168745, -0.023877939000838573, 0.004684831340306866, -0.006723659578830319, 0.016042192646555663, 0.015914364889044137, -0.02110411000418891, -0.007056007650540678, 0.027866117724008158, -0.0041000263811775545, -0.008851966502553729, 0.011466013130620581, -0.021819937623143295, -0.0010737403806936078, 0.00876248781735377, -0.00043341080983034234, -0.0015506918917835327, -0.01668132212088691, 0.02015819540194622, 0.029169945204405398, 0.006522333235622393, 0.02470880918011447, -0.02640889954230047, 0.005701049625932409, -0.0047008095771651475, 0.015172973394968196, -0.000989854404356972, -0.020286023159457746, 0.009222662715253018, 0.011619403831931024, -0.032621251816375235, -0.010258055071373026, -0.014815059585491003, -0.0039050912395806768, 0.017218192369441377, -0.008014704656005463, 0.02357115573557241, -0.002005274080819458, 0.009721184822818557, 0.037274128545610824, -0.032928036944286684, 0.013920276458781982, -0.010059924561801284, 0.014533842057991672, 0.020464978667212384, -0.0005456582089773255, 0.015543669607667485, -0.009037314608903373, -0.013089406279506085, -0.006832311868863422, -0.04629865981996946, 0.019685239963470155, 0.015454190922467527, 0.004822244270420348, 0.010334750422028248, -0.009350488610119268, -0.01339618861344961, 0.00036070964003986883, -0.008621879519265425, -0.016170018541421912, 0.006004637057562389, -0.0051737664126251725, -0.00807222593616622, 0.00035351942181210933, -0.010245272668150928, -0.024146374125115805, 0.013306710859572291, -0.0017336432393213694, -0.04944318502931841, -0.025245679428668937, -0.034870995761660445, -0.018458106902405496, -0.014597755005424796, -0.018279151394650858, -0.035458995623103305, -0.023200461385518397, 0.00905009701212547, -0.012034839852891612, 0.007043225247318581, -0.01028361987781722, -0.0030901990643324006, -0.04136456835720246, -0.007318051573206864, 0.00999601068304552, -0.030320381983492198, 0.0021634589982454967, 0.008820010028837167, 0.05982267525960796, 0.01950628259307024, 0.016745236930965312, 0.014521059654769575, -0.0011536316814003435, 0.01171527418440335, -0.005681876021099263, -0.0027866118655330797, -0.02924664148638326, 0.010430619843177934, -0.03042264307191425, 0.0038603521298113575, 0.013332275666016486, 0.020055936176169444, 0.01122314281278754, 0.025015592445380635, -0.006979312299885456, 0.01839419395497237, -0.0011408490453475866, -0.02314932990998473, -0.006468007323436501, -0.0165407147541212, -0.0026571878210180787, -0.020094282454513095, -0.009976837543873695, -0.0021986110727675832, 0.005256853896214082, -0.007950791708572338, -1.5141915494803277e-05, -0.0021394914101274154, 0.015914364889044137, 0.015645929764766902, 0.025846462624656532, -0.02469602770821501, 0.0025788940878834457, 0.026945769790854942, 0.018700977220238536, -0.013945841265226177, -0.01270592673226206, 0.00786131302337238, 0.0017911649851434454, 0.016617409173453786, 0.015709842712200026, 0.033899514490328284, -0.004662461901837537, 0.003253177499382056, -0.0026939378123582575, 0.028402987972562625, -0.020899587827344798, -0.03210994823691024, -0.0023344265517242927, -0.018777673502216395, -0.03356716641861793, -0.013204449771150236, -0.006781181324652395, -0.027508204845853604, 0.0002528562502081464, -0.007759051934950326, -0.012840144294400675, 0.027891682530452353, -0.03093394665137925, -0.03216107784979863, 0.00970840241959646, 0.025258462763213675, 0.027150291967699053, -0.007912443567583409, 0.014201493986281313, 0.025846462624656532, -0.005835267188071026, -0.034794299479682586, 0.001757610594608791, -0.01666854064898745, -0.016400105524710218, 0.01852201984983862, 0.007592877899095147, -0.017767845952540582, -0.01204123058884134, -0.005320766843647206, 0.014904538270690961, -0.02499002763893644, -0.022868113313808038, 0.029425598856783176, 0.01004075049130682, -0.007298877502712398, -0.0013110177568326662, -0.003793243348742049, -0.03402734038519453, 0.03543342895401383, 0.0035983084399758315, -0.016464018472143342, -0.01306384054173925, -0.01787010704096264, -0.006640572560902729, 0.009088445153114402, -0.02588481076564546, 0.02855637867387307, 0.025590810834924035, -0.011319012233937227, 0.001057762027419997, -0.0012407133749578333, -0.006027006496031719, 0.009663662611335161, -0.019723586241813806, 0.03924265403207406, -0.030831685562957196, 0.0172821053168745, 0.007068790519424094, 0.0031157643364379145, -0.026638986525588777, 0.001408485211215775, -0.013894710721015148, 0.03267238515455418, -0.02142367660399981, -0.02335385208682884, -0.00970840241959646, 0.015991061171021996, 0.028172900989274323, 0.01462332074319163, -0.010948316952560577, -0.016412886996609675, -0.018049064411362552, -0.01880323830866059, 0.016157235206877178, 0.005029962280900642, -0.010711838301999906, -0.013421754351216444, -0.023916287141827502, -0.00929935806590824, -0.03510108088230347, -0.008717748940415111, 0.015748190853188956, 0.04650318199681357, -0.017844542234518444, -0.016195583347866107, 9.716791046333955e-05, 0.018010716270373622, 0.01151075200755924, -0.029144380397961207, 0.008717748940415111, 0.015300799289834445, -0.01813854216523987, 0.011945361167691654, -0.017818975565428972, 0.00659583321830275, -0.00546776680900792, 0.009919315332390299, 0.012060404659335807, -0.02268915594340812, 0.006781181324652395, -0.0031621013630253256, -0.02761046593427566, -0.005522093186855132, -6.790768127068968e-05, 0.005189745115144773, -0.001206360026014133, -0.014981233621346183, 0.025974290382168058, -0.006014224092809622, -0.00810418334120542, -0.008615487851993057, -0.032212211187977575, 0.02022211021202462, -0.011517143674831608, 0.032800211049420436, 0.008110574077155151, -0.009702010752324092, -0.026306638453878418, -0.016988105386153075, 0.0067364424477137355, -0.006436050849719939, -0.02807063990085227, 0.0010905174595456052, -0.0020691870282525822, 0.005934332908518216, -0.003152514327778093, -0.030320381983492198, 0.007663182513800639, -0.04105778322929102, -0.03305586283915293, 0.02543742013361359, 0.016195583347866107, -0.0030214925992756597, 0.012469449013024025, 0.035484562292192774, 0.0015419039313606761, 0.016476801806688077, -0.00659583321830275, -0.005442201536902407, -0.012840144294400675, -0.024798288796637067, -0.008698574869920647, -0.013217232174372333, -0.004269396250668918, 0.03126629658573489, 0.023366635421373575, -0.010251663404100657, -0.027303682669009496, 0.009797880173473779, -0.032340037082843824, -0.010679881828283343, 0.004652874866590304, -0.0021842307527273944, 0.001394903733169302, -0.014150363442070286, -0.005199331684730686, 0.03671169162796688, -0.007822964882383451, 0.017882890375507374, 0.0003137734528533381, -0.009452749698541322, 0.017729497811551653, 0.006979312299885456, -0.0033362645173096455, -0.015786538994177885, -0.015109060447535072, -0.019800282523791665, -0.009414401557552392, 0.011108099321143388, -0.027099160492165385, 0.03568908446903689, 0.001538708214139822, -0.00015189351285653995, 0.0004098428464359462, -0.00913318403005306, -0.023890722335383308, 0.001265479688654301, 0.035458995623103305, 0.013204449771150236, -0.008059443532944122, -0.006170811093417569, -0.008263965709788233, -0.004454743891357243, -0.009676445945879898, 0.02458098328524822, -0.0022465460161730866, 0.034564210633749, 0.006196376365523082, -0.01519853820141239, 0.03420629961823973, -0.022331243065253567, 0.02270193741530758, -0.0022018069064037673, -0.005780941275885134, 0.01093553361801584, -0.008289530516232426, 0.0009011749103967201, -0.016642975842543258, 0.0008867944739412011, -0.019186717855904617, 0.011331795568481963, 0.018585932797271745, -0.0042374393112910354, 0.003267558052252905, 0.0018646650842391323, 0.0054997232827244825, -0.03845012826849654, 0.013089406279506085, -0.009842619981735077, -0.013102188682728182, -0.03405290705428401, 0.03157307798835577, -0.0007861313023372381, -0.01629784443628816, -0.005828875986459977, 0.0048605924114092786, -0.006384920305508911, 0.005371897387858234, -0.021819937623143295, 0.01629784443628816, -0.01323001457759443, 0.002110730537216377, 0.06825920667252373, -0.0157354093812895, -0.00807222593616622, 0.011408490919137185, -0.017767845952540582, 0.006132463418089958, 0.02060558789662337, 0.23929070103843184, -0.02408246117768268, -0.021986111658998473, 0.024350896301959916, -0.0024366874073156876, 0.015863235276155747, 0.010929142882066112, -0.006615007288797215, 0.007918835234855776, 0.03198212234204399, -0.021244719233599895, 0.0033905906623261975, -0.008864748905775826, -0.0007158268622547403, -0.012693144329039962, -0.023379416893273032, -0.02499002763893644, 0.013933058862004079, -0.03157307798835577, -0.016221148154310302, -0.0021698501998565455, -0.008347052727715822, -0.016566279560565396, -0.0009834630863305937, 0.01917393452135988, -0.0032052427888072123, -0.015799322328722623, 0.011248708550554374, 0.0037740695110782436, -0.0018790455206946514, -0.0247471573211034, 0.0016968932479811908, 0.011664143640192323, 0.0007302073569179242, -0.0035791343694813664, -0.01826636806010612, 0.018918282731627382, 0.020107065789057833, 0.03752978033534332, 0.029885772823359785, 0.005518897353218948, 0.0006147642696539193, -0.0010937131767664592, -0.00577774544224895, -0.006260289778617527, -0.001366142860258264, -0.0026092528776125758, -0.024261418548082597, -0.03515221422048242, 0.030652730055202557, -0.026817942033343416, -0.012507796222690317, 0.013383406210227513, 0.06370859289435549, 0.0025852855223251537, 0.013549580246082693, -0.002252937217784135, -0.0070943557915296085, -0.027226986387031634, 0.012552536030951616, 0.005502919116360667, 0.036609432402190105, -0.022433502291030343, 0.028147336182830128, -0.01766558486411853, 0.004831831305667581, -0.026715682807566636, 0.009510271910024718, -2.0746796126562398e-05, -0.006627790157680632, -0.006640572560902729, 0.0033362645173096455, 0.008577139711004126, -0.012859318364895142, -0.045199356379061605, -0.03453864768995009, 0.027891682530452353, -4.6736465774164525e-05, 0.034922125374548835, 0.032391166695732214, -0.009561401522913106, 0.006237919874486878, 0.01974915291090328, -0.004355678636571372, -0.026562290243610915, -0.024874985078614926, 0.0007222181802811188, -1.571613501898833e-05, -0.04021413157811567, -0.013485667298649568, 0.010884403073804814, -0.012469449013024025, -0.004790287796703786, -0.016400105524710218, 0.016489583278587534, 0.01913558638037095, -0.004058482872213759, 0.01110170765387102, -0.017972368129384693, 0.016285061101743426, -0.02043941386076819, 0.004016939363249965, -0.007241355756890323, 0.01412479863562609, -0.005975876417482011, 0.01445714670733645, -0.003978591222261034, -0.004288569855502063, 0.02346889650979563, -0.004739157252492758, -0.027661595547164047, -0.01606775745299986, 0.014188711583059217, 0.009676445945879898, 0.008877531308997924, 0.002687546377916549, 0.0053846797910803304, -0.009772315367029584, 0.0011640175586412921, -0.003946634748544471, 0.008500444360348905, -0.00018764490804882466, -0.0074906168106730914, 0.008883922976270291, 0.025552462693935102, -0.018790454974115852, -0.011293447427493034, -0.005352723317363768, 0.011082534514699195, -0.03965169466047172, 0.0222801115897199, -0.03678838790994474, 0.023647852017550267, -0.029067684115983344, -0.009280183995413775, 0.003285133973098618, 0.006819529465641325, 0.015786538994177885, -0.0184325420959613, 0.0011520338809975813, 0.016694105455431645, -0.0032308078280820665, -0.0007901258615518084, -0.011613013095981294, -0.01438045042535859, -0.009817054243968244, 0.014303755074703368, -0.025974290382168058, -0.004314135127607577, -0.006055767601773417, -0.022957591067685357, -0.0009243434236904256, -0.013460101560882735, 0.003061438191421363, 0.013702971878715775, -0.010724620705222001, -0.03579134369481366, -0.025999855188612253, 0.003863547730616882, 0.024759940655648134, -0.034436384738882754, -0.0007593677090334853, 0.04461135279232819, -0.03405290705428401, -0.022011676465442668, -0.013332275666016486, -0.1620836519229462, 0.025769768205323947, 0.0018103389392225807, -0.026229942171900555, 0.03556125857417064, 0.02380124458150599, 0.02486220174407019, -0.0052408751936944805, -0.009235445118475115, 0.013447319157660637, 0.026638986525588777, -0.021960546852554278, -0.017218192369441377, 0.00023128558097295168, 0.009209879380708282, 0.009292966398635872, -0.0015730615630835222, -0.005601984371146538, 0.0023759700606880876, 0.01429097267148127, 0.02511785353380269, -0.03223777413177649, 0.026434464348744666, 0.020170978736490958, 0.002062795826641534, 0.012245752765685451, -0.0056435278801103324, 0.0007589682298289622, -0.015786538994177885, 0.0021027414187872366, -0.017729497811551653, -0.001031397913320767, 0.0200687176480689, 0.0061068981459844445, 0.028121769513740656, -0.00700487757199097, -0.023507242788139284, -0.012744274873250989, -0.019199499327804074, 0.0074906168106730914, 0.009695619085051723, 0.008136139814921983, 0.016285061101743426, -0.010091881035517846, -0.028837597132695042, -0.0052408751936944805, 0.013958624599770913, 0.026281071784788945, -0.009312140469130337, -0.008941445187753687, -0.004224656908068939, -0.010027968088084722, 0.011248708550554374, 0.02625550697834475, 0.010903577144299278, 0.027917249199541826, 0.01815132363713933, 0.008065835200216491, 0.005256853896214082, 0.004911722955620306, 0.010258055071373026, 0.005244071027330665, 0.019352891891759795, 0.012418318468812998, 0.008864748905775826, 0.002572502886272397, -0.009970445876601326, 0.013677406140948941, -0.021768806147609628, 0.013498449701871666, -0.002297676560384114, -0.02118080628616677, -0.004930896560453452, -0.03405290705428401, 0.02383959085984964, -0.008954227590975784, -0.027175856774143244, 0.03847569493758601, -0.006723659578830319, 0.013830797773582024, -0.003387395061520673, 0.02493889802604805, -0.020477762001757122, 0.0006950551077728428, -0.0023472091877770494, 0.015824887135166818, 0.011664143640192323, -0.020784545267023287, -0.015224103939179223, -0.018905499397082644, 0.03433412551310598, -0.02155150249886606, -0.006113289347595492, -0.01609332225944405, 0.024274200019982057, 0.02617881255901217, -0.0038156130200420386, 0.007669573715411688, 0.019186717855904617, -0.0015051538236051675, -0.013881928317793052, 0.00432372216285481, -0.011983709308680585, 0.010865229934632988, 0.014661668884180561, 0.0029144379932299885, 0.01229049164262411, 0.013792450563915733, 0.022382372678141957, -0.028990987834005486, -0.0006307425647198654, 0.008877531308997924, 0.02106576186319998, 0.03494769204363831, 0.031803166834289354, 0.0443045713897073, -0.011146447462132319, -0.014572190198980603, 0.011702490849858613, -0.0030630361082394546, 0.041569090534046574, -0.013971407002993009, -0.03075499114362461, -0.0021490784453746478, -0.003643047549745151, -0.0035088299876065336, -0.04696335596339018, -0.028888728608228706, 0.023008720680573743, 0.006426463814472706, 0.004608135523990325, 0.01978750105189221, 0.023366635421373575, 0.011613013095981294, -0.036558302789301715, -0.0013549580246082693, -0.013447319157660637, -0.0129487970500951, -0.004982027104664479, -0.011542708481275803, 0.028837597132695042, -0.025258462763213675, -0.01089718640834955, -0.010085489368245479, -0.0008160905546541802, 0.01738436640529656, -0.0025852855223251537, 0.001481186468317746, 0.014559407795758506, -0.03213551490599972, -0.01609332225944405, 0.016310625908187618, -0.007759051934950326, 0.044048919599974805, 0.009772315367029584, 0.009606141331174404, -0.018291932866550314, -0.005832071820096161, -0.006704485508335854, -0.010437011510450303, -0.007874095426594478, -0.00946553210176342, -0.04619640059419268, 0.007215790484784808, 0.005710636661179641, -0.008794444291070333, 0.02470880918011447, 0.025744203398879756, -0.0002336823252328436, -0.0242358537416384, 0.006774790123041346, 0.008379009201432384, -0.002267317770654984, 0.03379725526455151, 0.00389230860352792, -0.016080538924899315, -0.01581210380062208, -0.011970925974135849, -0.04105778322929102, 0.009900141261895833, 0.05184631781326878, 0.0031093731348268657, 0.014099232897859259, 0.02773829182914191, -0.02224176344873097, -0.003139731691725336, 0.00011744034504341571, 0.005621158441641003, -0.027226986387031634, 0.009107619223608867, 0.004438765654498962, 0.0014747951502913676, -0.0025868832063125863, 0.004739157252492758, -0.0003227612401899537, 0.004630504962459655, 0.002395143898351893, 0.03303029617006346, -0.01802349774227308, 0.03747865072245493, -0.010500924457883427, -0.0026635790226291274, -0.030499337491246836, -0.022331243065253567, 0.010181358789395165, -0.016821931350297893, -0.022356807871697762, -0.021142458145177838, -0.008941445187753687, 0.006640572560902729, 0.016655757314442715, -0.0007789410841094786, -0.004093635179566506, -0.00717105160784615, -0.010194142123939902, -0.014661668884180561, 0.011088925250648923, 0.0031205578540615306, 0.0045857660855209955, 0.003879525967475163, -0.005359114518974817, 0.006857877140968936, -0.003949830582180656, 0.0059918546543402925, 0.022804198503729636, 0.012552536030951616, -0.005534875590077229, -0.042719527313133374, -0.06841259923647947, 0.02519454981578055, -0.006030202329667903, -0.04522491932286052, 0.0034033732983789543, 0.0021474807613872157, 0.018547586518928093, -0.02022211021202462, 0.0004925304433666779, -0.01971080476991435, -0.00880722762561507, -0.0031333404901142878, 0.004221461074432754, -0.004186309232741328, -0.029067684115983344, -0.03464090691572687, 0.03356716641861793, 0.006311419857167234, 0.024031331564794294, 0.01462332074319163, 0.002367980942258947, -0.011037794706437896, 0.00040065534860090154, 0.024389244442948845, -0.014393233759903326, 0.009983228279823423, -0.0190077604855047, 0.0033682212238568677, 0.0020803719803179073, -0.0024334918065101636, 0.015556452010889583, -0.029067684115983344, 0.02261245966143026, 0.01790845518195157, -0.011459621463348212, -0.002280100406707741, 0.0062443110760979255, 0.012316057380390943, -0.005145005772544794, 0.024555418478804027, -0.038577954163362786, -0.024248635213537862, 0.019889762140314265, 0.008155312954093809, -0.005125831702050328, 0.011766404728614377, 0.011421273322359283, 0.017972368129384693, 0.03520334383337081, -0.012130709274041298, 0.008078617603438589, 0.021372545128466144, -0.00401374352961378, -0.0012127513440405116, -0.016617409173453786, -0.02015819540194622, 0.01620836668241084, -0.007433095064851016, 0.02781498811111977, -0.03326038501599704, 0.02909324892242754, -0.012597274907890275, 0.006305028655556186, 0.008922271117259222, -0.00659583321830275, 0.00015748590157770484, -0.015837670469711553, -0.015492539063456458, 0.003441721206537225, -0.029809076541381922, -0.022919242926696424, -0.0032787427714875694, -0.008730531343637209, 0.007886878761139214, 0.008717748940415111, 0.010053532894528917, 0.008014704656005463, 0.006557485542975139, -0.009631706137618599, 0.025462984940057783, -0.001847089046978089, -0.00015798523603144236, -0.013536797842860595, -0.01921228266234881, 0.011248708550554374, 0.019813065858336403, -0.0212191544271557, 0.011088925250648923, 0.008040269462449658, 0.013242796980816528, -0.05895345693934313, 0.0005037152208090076, 0.006979312299885456, 0.007880487093866847, 0.005279223334683412, 0.01668132212088691, 0.022024459799987402, -0.0007038431846110294, 0.041569090534046574, 0.005365506186247185, 0.00942718396077449, -0.0037325260021144487, 0.005224896956836199, 0.004787092428728921, -0.01495566881490199, 0.0026683725402527436, -0.01438045042535859, -0.024159157459660543, -0.004870179446656511, 0.017550540441151737, -0.008736923010909578, 0.0006766801121027535, 0.0006894627481555104, 0.02339220022781777, -0.015109060447535072, -0.004755135955012359, -0.0006802751921128009, -0.014700016093846852, -0.021206371092610962, 0.025948723713078586, 0.006487180928269646, 0.0025741008030904892, 0.022625242995974997, -0.005122636334075464, 0.02467046290177082, -0.010270837474595123, -0.020349936106890874, -0.015530887204445388, 0.012763448943745455, 0.007765443602222694, -0.0029863402919229134, -0.00037289308638967364, -0.017742281146096387, -0.021385328463010878, -0.006365746235014446, 0.04011187235233889, 0.004803070665587202, 0.019071673432937825, -0.03653273612021224, 0.06713433283723585, 0.013012709997528224, -0.013083014612233716, 0.00892866185320895, 0.01081409939042196, 0.009312140469130337, 0.009823445911240613, 0.0004821445661257292, -0.015262452080168154, -0.0194934992585255, 0.003457699443395506, -0.01339618861344961, -0.017103149809119866, -0.04591518213537071, -0.021577067305310255, 0.0024462744425629204, -0.02190941537702061, 0.009030922941631006, -0.01609332225944405, 0.016131670400432983, 0.022292894924264638, 0.0051577881757668914, -0.007362790915806843, 0.02110411000418891, -0.01885436792154898, -0.014687233690624754, 0.0077398783301171805, -0.006285854585061721, -0.012341622186835138, -0.02281698183827437, -0.011504360340286872, 0.0026635790226291274, -0.026012638523156988, -0.014968451218124085, -0.006621398490408264, -0.012546144363679247, -0.011951752834964023, -0.01499401695589092, 0.0062666809802285756, 0.012757057276473086, 0.008839184099331631, 0.0062219416376285966, -0.008302313850777163, -0.004640091997706887, 0.024811070268536524, -0.0010673490626672295, -0.02155150249886606, 0.007893269497088943, 0.01934010855721506]\n"
     ]
    }
   ],
   "source": [
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XeAm0wWjhFEI"
   },
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "  return embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHnI3mIgg9lp"
   },
   "outputs": [],
   "source": [
    "df['embedding'] = df.apply(lambda row: get_embedding(\n",
    "        row.text\n",
    "    ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "msIEV-9ohJXh",
    "outputId": "a0edaaed-696e-4cf0-f942-addd0053e210"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\\uc800\\ub294 \\ubc30\\uac00 \\uace0\\ud30c\\uc694\",\n          \"\\uc800\\uae30 \\ubc30\\uac00 \\uc9c0\\ub098\\uac00\\ub124\\uc694\",\n          \"\\uc2a4\\ud300\\uc5d0\\uc5b4\\ud504\\ub77c\\uc774\\uc5b4\\ub85c \\uc5f0\\uc5b4\\uad6c\\uc774 \\ud574\\uba39\\uc744\\uac70\\uc57c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ca3343de-d82e-4203-82ab-17194c4085e7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>저는 배가 고파요</td>\n",
       "      <td>[-0.016637360179694076, -0.02178889820399648, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>저기 배가 지나가네요</td>\n",
       "      <td>[-0.0032914344795325024, -0.027514765824463994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>굶어서 허기가 지네요</td>\n",
       "      <td>[-0.006181030746934311, -0.006950793503402665,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>허기 워기라는 게임이 있는데 즐거워</td>\n",
       "      <td>[-0.011329255872108568, -0.011715852525143846,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스팀에서 재밌는 거 해야지</td>\n",
       "      <td>[-0.01610845668785982, -0.014401600417918041, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>스팀에어프라이어로 연어구이 해먹을거야</td>\n",
       "      <td>[-0.0021389091187001565, -0.030034279922246478...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca3343de-d82e-4203-82ab-17194c4085e7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ca3343de-d82e-4203-82ab-17194c4085e7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ca3343de-d82e-4203-82ab-17194c4085e7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ae644779-6ab4-48ce-b08a-474cd1c2acda\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae644779-6ab4-48ce-b08a-474cd1c2acda')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ae644779-6ab4-48ce-b08a-474cd1c2acda button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_23830c90-70ef-4fcc-9f86-96a1b2132741\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_23830c90-70ef-4fcc-9f86-96a1b2132741 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   text                                          embedding\n",
       "0             저는 배가 고파요  [-0.016637360179694076, -0.02178889820399648, ...\n",
       "1           저기 배가 지나가네요  [-0.0032914344795325024, -0.027514765824463994...\n",
       "2           굶어서 허기가 지네요  [-0.006181030746934311, -0.006950793503402665,...\n",
       "3   허기 워기라는 게임이 있는데 즐거워  [-0.011329255872108568, -0.011715852525143846,...\n",
       "4        스팀에서 재밌는 거 해야지  [-0.01610845668785982, -0.014401600417918041, ...\n",
       "5  스팀에어프라이어로 연어구이 해먹을거야  [-0.0021389091187001565, -0.030034279922246478..."
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXs4ps9bhL9O"
   },
   "source": [
    "벡터의 유사도를 구하는 방법으로는 코사인 유사도가 있다.  \n",
    "코사인 유사도: https://wikidocs.net/24603  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQvCAR7IhNhc"
   },
   "outputs": [],
   "source": [
    "def cos_sim(A, B):\n",
    "  return dot(A, B)/(norm(A)*norm(B))\n",
    "\n",
    "def return_answer_candidate(df, query):\n",
    "    query_embedding = get_embedding(\n",
    "        query\n",
    "    )\n",
    "    df[\"similarity\"] = df['embedding'].apply(lambda x: cos_sim(np.array(x),\n",
    "                                                            np.array(query_embedding)))\n",
    "    results_co = df.sort_values(\"similarity\",\n",
    "                                ascending=False,\n",
    "                                ignore_index=True)\n",
    "    return results_co.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "N3Z5Gd29hO-R",
    "outputId": "da7a9167-4494-4c68-ae35-64d5fca974ff"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"sim_result\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\uad76\\uc5b4\\uc11c \\ud5c8\\uae30\\uac00 \\uc9c0\\ub124\\uc694\",\n          \"\\uc2a4\\ud300\\uc5d0\\uc5b4\\ud504\\ub77c\\uc774\\uc5b4\\ub85c \\uc5f0\\uc5b4\\uad6c\\uc774 \\ud574\\uba39\\uc744\\uac70\\uc57c\",\n          \"\\uc800\\ub294 \\ubc30\\uac00 \\uace0\\ud30c\\uc694\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012338071584528936,\n        \"min\": 0.8142589316960948,\n        \"max\": 0.8383326491909124,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8383326491909124,\n          0.8216025904946773,\n          0.8142589316960948\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "sim_result"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-bbe03a18-775b-4593-96d4-ddbdd02fe1ae\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>굶어서 허기가 지네요</td>\n",
       "      <td>[-0.006181030746934311, -0.006950793503402665,...</td>\n",
       "      <td>0.838333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스팀에어프라이어로 연어구이 해먹을거야</td>\n",
       "      <td>[-0.0021389091187001565, -0.030034279922246478...</td>\n",
       "      <td>0.821603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저는 배가 고파요</td>\n",
       "      <td>[-0.016637360179694076, -0.02178889820399648, ...</td>\n",
       "      <td>0.814259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbe03a18-775b-4593-96d4-ddbdd02fe1ae')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bbe03a18-775b-4593-96d4-ddbdd02fe1ae button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bbe03a18-775b-4593-96d4-ddbdd02fe1ae');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-122aed83-246f-44ad-a767-4585adfaf766\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-122aed83-246f-44ad-a767-4585adfaf766')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-122aed83-246f-44ad-a767-4585adfaf766 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_7fc9a9cd-8504-4acd-bde1-3b9f15d924a8\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sim_result')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_7fc9a9cd-8504-4acd-bde1-3b9f15d924a8 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('sim_result');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   text                                          embedding  \\\n",
       "0           굶어서 허기가 지네요  [-0.006181030746934311, -0.006950793503402665,...   \n",
       "1  스팀에어프라이어로 연어구이 해먹을거야  [-0.0021389091187001565, -0.030034279922246478...   \n",
       "2             저는 배가 고파요  [-0.016637360179694076, -0.02178889820399648, ...   \n",
       "\n",
       "   similarity  \n",
       "0    0.838333  \n",
       "1    0.821603  \n",
       "2    0.814259  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_result = return_answer_candidate(df, '아무 것도 안 먹었더니 꼬르륵 소리가나네')\n",
    "sim_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMw7AbndjM2Q"
   },
   "source": [
    "## 5-2. 벡터 저장소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KpER3VHHm8BT",
    "outputId": "63453548-062b-4087-f9bb-bf47552b27ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.33.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.28.2)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.20.3)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.6)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.29.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.26.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m105.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.50b0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.29.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.29.0-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.33.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=b514289d00a118b8933f3d3dec71c47b1802d15729a3210fbdf13cd3305757e5\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, mmh3, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: opentelemetry-api\n",
      "    Found existing installation: opentelemetry-api 1.28.2\n",
      "    Uninstalling opentelemetry-api-1.28.2:\n",
      "      Successfully uninstalled opentelemetry-api-1.28.2\n",
      "  Attempting uninstall: opentelemetry-semantic-conventions\n",
      "    Found existing installation: opentelemetry-semantic-conventions 0.49b2\n",
      "    Uninstalling opentelemetry-semantic-conventions-0.49b2:\n",
      "      Successfully uninstalled opentelemetry-semantic-conventions-0.49b2\n",
      "  Attempting uninstall: opentelemetry-sdk\n",
      "    Found existing installation: opentelemetry-sdk 1.28.2\n",
      "    Uninstalling opentelemetry-sdk-1.28.2:\n",
      "      Successfully uninstalled opentelemetry-sdk-1.28.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 humanfriendly-10.0 kubernetes-31.0.0 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.1 opentelemetry-api-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-sdk-1.29.0 opentelemetry-semantic-conventions-0.50b0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.1 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.41.3 uvicorn-0.33.0 uvloop-0.21.0 watchfiles-1.0.3\n"
     ]
    }
   ],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfBnMoeRmrLx"
   },
   "source": [
    "크로마는 오픈소스 벡터 데이터베이스입니다. Chroma는 Apache 2.0 라이선스가 부여됩니다.\n",
    "\n",
    "- 공식 도큐먼트\n",
    "- 홈페이지\n",
    "\n",
    "**Apache 2.0 License 에 대해**\n",
    "\n",
    "Apache 2.0 라이선스는 오픈 소스 라이선스 중 하나로, 누구나 소프트웨어를 자유롭게 사용, 수정, 배포할 수 있도록 허용하는 라이선스입니다.\n",
    "\n",
    "이 라이선스의 주요 특징은 다음과 같습니다:\n",
    "\n",
    "- 상업적 사용 가능: Apache 2.0 라이선스 하에 배포된 소프트웨어는 상업적 목적을 포함하여 어떤 목적으로든 사용할 수 있습니다. 이는 기업이나 개인이 이 라이선스로 된 소프트웨어를 상업적 제품이나 서비스에 통합하는 것을 가능하게 합니다.\n",
    "\n",
    "- 소스 코드 공개 의무 없음: 소프트웨어를 수정하거나 확장한 경우, 그 변경된 소스 코드를 공개할 의무가 없습니다. 하지만 원본 소프트웨어가 Apache 2.0 라이선스를 따른다면, 변경된 버전 역시 Apache 2.0 라이선스 하에 배포되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPOsgkbNjUiQ"
   },
   "outputs": [],
   "source": [
    "script = '''허수현은 한반도 최북단 탄광마을이 낳은 수재였다. 그는 고등학교 졸업 직전 북한 전체에서 700명에게만 수여하는 ‘7.15 최우등상’을 수상했다. 7.15최우등상은 김정일이 평양 남산고급중학교를 졸업한 날인 1960년 7월 15일을 기념해 1987년에 만들어진 상이다.\n",
    "\n",
    "지금은 이 상이 특권층 자식들을 대학에 보내기 위한 발판이 돼 각종 비리와 뇌물로 얼룩져 있지만, 상이 제정된 초기 몇 년은 정말 공부 잘하는 사람에게만 수여됐다. 상을 받게 되면 곧바로 중앙급 대학에 진학할 수 있었다. 북한에선 고등중학교 졸업생 중 20% 미만이 대학이나 전문학교에 갈 수 있다는 것을 감안하면 엄청난 특혜였다.\n",
    "\n",
    "허 씨도 김책공업종합대학(김책공대)에 입학해 8년이나 공부했다. 그리고 그때 배운 지식을 활용해 지금은 한반도 최남단인 경남 마산의 해저터널 공사장에서 시공품질을 관리하는 공사차장으로 일하고 있다. 김책공대 졸업생이 네 번의 탈북을 반복한 뒤 건강이 악화돼 남의 등에 업혀 동남아 정글을 넘어 한국까지 오게 되고, 이후 남과 북에서 동시에 측량기사 자격을 받은 최초의 기술자가 돼 해저터널 공사장에서 일하게 되기까지 삶의 과정은 결코 순탄하지 않았다.\n",
    "\n",
    "\n",
    "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
    "\n",
    "\n",
    "● 신분 상승의 꿈\n",
    "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
    "\n",
    "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
    "\n",
    "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
    "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
    "\n",
    "아버지가 사망하자 허 씨는 1년 정도 방황했다. 학교에도 나가지 않았다. 하지만 곧 마음을 다잡고, 부친의 소원대로 신분 상승을 하기로 결심했다. 3년을 열심히 공부해 고등학교 졸업반이 됐을 때 허 씨는 7.15 최우등상을 받을 정도로 공부를 잘하게 됐다. 북한도 대도시의 교육 환경이 매우 좋기 때문에 외진 탄광마을에서 수상자를 배출한다는 것은 하늘의 별 따기였다.\n",
    "\n",
    "하지만 상을 받아도 문제였다. 평양에서 대학을 다닌다는 것은 가족들에겐 엄청난 희생이 필요한 일이었다. 그런데 그가 김책공대에 입학한 1992년엔 탄광마을에 배급이 제대로 공급되지 않았다. 평양에서 대학을 다닐 돈이 나올 리 만무했다.\n",
    "\n",
    "허 씨는 대학 대신에 군대에 가려고 시도했다. 대학을 갈 사정이 못되니 군에 입대해 노동당원이 되면 신분이 그나마 좀 바뀔 것이라고 생각했던 것이다.\n",
    "\n",
    "하지만 7.15 최우등상 수상자는 군대에 보내지 않는다는 지침이 있어 결국 갈 수는 없었다. 그는 울며 겨자 먹기로 김책공대 지질탐사학부에 입학했다.\n",
    "\n",
    "그해 온성에서 중앙대학에 입학한 사람은 단 두 명이었다. 허 씨 외에 이과대학 입학생이 한 명 더 있었다. 온성군은 그런 동네였다.\n",
    "\n",
    "● 돈에 성적을 뺏기던 시절\n",
    "북한의 다양한 산업현장에서 활약하는 인재들을 키우는 김책공대는 학제가 길어 7년을 다녀야 졸업증을 받을 수 있다. 그런데 대학을 다니며 각종 공사현장에 끌려 다니다 보니 진도가 밀려 7년 안에 졸업하기가 어렵다. 허 씨도 학제보다 1년을 더 다녀 2000년에야 졸업할 수 있었다.\n",
    "\n",
    "그가 대학을 다니던 1990년대 중반은 북한에서 고난의 행군 시기라 사방에서 아사자가 속출할 때였다. 대학 기숙사에서 주는 밥을 먹으면 굶어죽을 수밖에 없었다.\n",
    "\n",
    "탄광마을에서 태어나 김책공대에 입학한 허 씨와, 어촌마을에서 태어나 김일성대에 입학한 기자는 평양에서 대학을 다닌 시기가 정확히 겹친다. 그래서 인터뷰 내내 떠올리기 싫은 추억들이 소환됐다. 몇 개를 소개하면 이런 식이다.\n",
    "\n",
    "“1993년 공화국 창건 행사 때 김일성대 학생들은 깃발을 들고 김일성광장을 통과했습니다. 그 연습만 3개월 하면서 너무 힘들어 죽을 뻔 했죠.”\n",
    "\n",
    "“김책공대는 촛불을 들고 김일성대를 따라갔죠. 저도 죽을 뻔 했어요.”\n",
    "\n",
    "“제대군인인 학급 소대장, 청년단체비서 이런 사람들은 가난한데 공부 잘하는 학생들을 곁에 한둘씩 끼고 있죠. 그리곤 시험 때마다 자기 것도 좀 써달라고 사정하죠. 그걸 거절하기 어려워 저는 시험 칠 때마다 시험지 3개를 써주었어요. 다양한 볼펜을 준비해서 한 장은 정자로 쓰고, 다른 장은 흘겨 쓰고, 이런 식으로 답을 적어 교수가 뒤돌아서 있을 때 공부 못하는 제대군인들에게 몰래 건네주었죠. 대신 그들은 각종 비용을 걷을 때 나를 빼주기도 했고, 가끔 도시락도 두 개를 갖고 와서 허기진 배도 채워주었습니다.”\n",
    "\n",
    "“저도 그랬어요. 국가졸업시험 때까지 남의 시험지를 작성해주었어요. 대신 저는 돈을 받았습니다. 방학 때 집에 가지도 않았지요. 온성까지 기차로 일주일 넘게 걸리는데 왔다갔다 시간 낭비가 크고, 또 가봐야 집에서 보태줄 수도 없으니 방학 때는 제대군인들 과외를 해주고 돈을 받았습니다.”\n",
    "\n",
    "“저는 졸업장을 받고 나니, 3점짜리 과목이 몇 개 있었어요. 저는 대학 내내 3점을 받은 적이 없거든요. 5점 만점에 3점은 낙제를 겨우 면한 수준인데, 대학 교무부에 찾아가 싸우지도 않았어요. 어차피 이 체제가 싫어서 탈북하려 결심한 마당에 3점이 대수냐고 생각했죠.”\n",
    "\n",
    "“저도 졸업증에 받지 않은 3점들이 있었어요. 권력자 부모를 둔 학생들은 좋은 곳에 가기 위해 대학 교무부 직원들에게 뇌물을 주고 컴퓨터에서 점수를 바꾸었어요. 5점 최우등생과, 4점 우등생, 3점 보통생의 전체 비율을 바꿀 수 없으니 5점으로 조작하려면 누군가의 점수를 빼앗아야 했죠. 제일 힘이 없는 우리가 점수를 빼앗긴 거였죠.”\n",
    "\n",
    "최우등을 하고도, 돈과 권력이 없으면 3점 졸업증을 받아야 했던 시대. 허 씨와 기자는 그 시대에 평양에서 대학을 다녔다. 기숙사에서 밥을 몇 숟가락만 주던 때라 대학 시절을 떠올리면 배고팠던 기억밖에 없다. 졸업증을 받은 것만으로도 기적이었다. 뇌물로 성적을 조작하고, 남의 졸업논문을 베껴 써서 제출하는 상황은 지금도 별반 나아지진 않았다.\n",
    "\n",
    "\n",
    "2018년 뉴질랜드로 한 달 동안 어학연수를 떠났던 시기의 모습.\n",
    "\n",
    "\n",
    "● 북한의 측량기사들\n",
    "아버지가 없는 가난한 탄광마을 출신의 김책공대 졸업생에게 좋은 직업이 기다릴 리 만무했다. 북한은 직업 선택의 자유가 없다. 대학을 졸업하면 중앙에서 어디로 가라고 임명한다.\n",
    "권력과 부를 가진 집안에서 태어나면 대학 때 실컷 놀고도 중앙당이나 외화벌이 업체, 보위부 등 권력기관에 발령을 받는다. 가난한 자들의 운명은 그와 반대이다.\n",
    "\n",
    "허 씨는 2000년 3월 대학을 졸업하면서 졸업증과 함께 측량기사 자격을 부여받았다. 그리고 평양 인근 대동군 시정노동자구에 있는 중앙측량단으로 발령을 받았다. 모두가 기피하는 직업이었다.\n",
    "\n",
    "측량기사는 20㎏이 넘는 장비를 메고 매일 같이 산을 오르내려야 했다. 1000분의 1 오차 범위 내에서 지도에 점 하나를 찍는데 사나흘이 걸렸고, 한 구역을 측량하는데 2~3개월이 걸렸다. 깊은 산속에 천막을 치고 야인생활을 하기 일쑤였다. 그나마 현장기사는 배급을 받을 수 있어 다행이었다.\n",
    "\n",
    "북한은 측량을 하는 기관이 두 개가 있다. 하나는 중앙측량단이고, 다른 하나는 인민무력부(군) 측지국이다. 그런데 진짜 좌표는 측지국이 갖고 있다. 중앙측량단의 좌표는 일부러 정확한 좌표와 다르게 작성한다. 좌표가 고급 비밀이기 때문에 외부에 정보가 새나가면 안된다는 이유 때문이다.\n",
    "\n",
    "허 씨는 한국에 온 뒤 큰 허탈감을 느꼈다. 위성으로 GPS를 찍는 시대를 보니 그 무거운 장비를 메고 다니며 점 하나를 찍겠다고 며칠씩 바친 과거가 너무 허망하게 생각됐기 때문이다. 북한도 2005년경부터 러시아 위성항법체계인 ‘글로나스’의 도움을 받아 위성 측량을 시도했다고는 알려졌지만, 어느 정도 활용되는지는 아직 파악되지 않고 있다.\n",
    "\n",
    "● 원시적 석탄채굴\n",
    "허 씨는 2001년 말에 온성으로 돌아왔다. 뇌물이 없으면 이직도 힘든 세상이지만, 아버지도 없는데 어머니마저 아파서 쓰러졌다고 하니 집으로 보내준 것이다. 실제로 어머니를 간호할 사람은 허 씨 밖에 없었다.\n",
    "\n",
    "새로 발령받은 직장은 풍인탄광 기술과였다. 그러나 할 일은 없었다. 1990년대 중반 고난의 행군 시기 온성 탄광들은 모두 침수됐다. 전기가 없어 물을 빼낼 수가 없었기 때문이다. 그렇게 몇 년을 방치하다보니 갱을 다시 사용할 수가 없었다.\n",
    "\n",
    "탄광에 다니던 사람들은 먹고 살기 위해 다른 방법을 찾았다. 일제 때 했던 방식대로 얇은 탄층 채굴을 시작한 것이다. 삽과 곡괭이로 수직굴을 파들어 가는데, 운이 좋으면 8m에서 탄층을 만나기도 하지만, 운이 나쁘면 25m까지 파들어 간다. 탄층을 만나면, 그걸 따라 이번엔 가로로 파 들어간다. 탄층의 두께는 보통 0.8~1.2m였다. 양동이를 매단 도르래를 타고 수직굴에 들어가 몸을 돌리기도 어려운 좁은 공간에서 석탄을 파서 다시 양동이로 끌어올렸다. 도무지 현대인이라고 볼 수 없는 원시적 채탄방식이었지만, 그렇게 해서라도 석탄을 캐서 팔아야 장마당에서 먹을 것을 사올 수 있었다. 이런 수직굴을 온성에선 ‘노두’라고 불렀다. 온성에는 이런 노두가 수없이 많았다. 노두당 가족, 친척, 친구 등 5~7명이 팀을 이뤄 작업했는데, 이런 사람들을 ‘노두공’이라 불렀다. 북쪽은 날씨가 춥기 때문에 먹는 것 못지않게 석탄도 귀하다. 캐내면 파는 것은 큰 문제가 안됐다.\n",
    "\n",
    "노두도 1년 내내 할 수 있는 것이 아니었다. 땅이 어는 1~3월에만 할 수 있었고, 봄이 와서 땅이 녹으면 수직갱이 버틸 수 없기 때문에 버려야 했다. 구멍을 방치해서도 안됐다. 단속기관 사람들이 찾아와 갱을 다시 메웠는지 조사한다. 단속할 권한이 있다는 것은 뇌물을 받을 수 있다는 것을 의미하기 때문에 얼렁뚱땅 넘어가지 않는다.\n",
    "\n",
    "온성 전체에 이런 노두가 수없이 생겨났다 사라졌다. 겨울이면 할 일이 없는 농민들도 이 일에 매달렸다. 안전은 뒷전이라 붕괴와 추락, 가스질식 등으로 죽는 사람들이 계속 생겨났지만 큰 문제가 되진 않았다. 그 일을 하지 않으면 어차피 굶어죽기 때문이다.\n",
    "\n",
    "허 씨가 소속된 기술과는 늘 각종 공사에 동원됐다. 도로 공사, 발전소 공사 등등 인력을 차출하는 공사는 끊이질 않았다. 김책공대에서 배운 지식을 쓸 곳은 없었다.\n",
    "\n",
    "이렇게 살다가 어느새 결혼할 나이가 됐다. 그래도 허 씨는 명색이 탄광마을이 배출한 수재이고, 평양에서 김책공대까지 나왔던 터라 여성들에게 나름 인기가 있었다.\n",
    "\n",
    "32살 때인 2006년 그는 10살 어린 여성과 결혼했다. 아내는 탄광 선전대 가수로 나름 인기가 좋았다. 이성적인 지식인과 감성적인 예술인의 조합이었다.\n",
    "\n",
    "그렇지만 매력과 결혼생활은 별개였다. 결혼한 직후부터 둘은 다투는 일이 많았다. 서로가 서로를 견디기 어려워했다. 4년간의 결혼생활 끝에 둘은 이혼하기로 합의했다. 어린 딸은 아내가 키우기로 했다. 이때부터 그는 중국으로 눈을 돌렸다.\n",
    "\n",
    "\n",
    "2022년 인천지하철 공사 현장에서 일하고 있는 허 씨.\n",
    "\n",
    "\n",
    "● 두만강을 넘나들다\n",
    "강 건너 연변 왕청에는 아버지의 삼촌과 사촌 등 친척들이 살고 있었다. 국경 근처라 많은 사람들이 중국을 드나들 때도 허 씨는 명색이 김책공대 졸업생인데 조국을 배반하면 안 된다는 마음이 컸다. 하지만 이혼 후 세상이 달리 보이기 시작했다. 이혼까지 한 마당에 눈치 볼 일도, 무서울 일도 없었다.\n",
    "\n",
    "2010년 겨울 그는 국경경비대에 돈을 쥐어주고 두만강을 넘었다. 탈북한 것은 아니고, 친척에게 도움만 받자는 목적이었다. 저녁에 넘어가서 친척에게 전화를 하고 새벽이 되기 전에 다시 북으로 넘어왔다.\n",
    "\n",
    "2012년 2월 그는 두 번째로 중국으로 갔다. 당시는 김정일이 사망한지 얼마 안됐던 때라 경계가 매우 심했다. 그는 북한군 군복을 입고 길을 떠났다. 군인은 초소에서 잘 단속하지 않았기 때문이다. 강을 따라 난 도로로 한참을 가다가 어둠이 내릴 때 바로 두만강을 넘었다. 중국 부락의 아무 집이나 들어가 왕청 친척에게 전화를 좀 하고 싶다고 했다. 전화를 하고 몇 시간 정도 머물렀는데 갑자기 공안이 들이닥쳤다. 집주인이 그를 도와주는 척하고는 신고를 했던 것이다. 알고 보니 중국은 그즈음부터 탈북자를 신고하면 포상금을 주는 제도를 운영하고 있었다. 특히 북한군 국경경비대가 수시로 건너와 사람까지 죽이며 노략질을 했기 때문에, 중국에서 북한군은 최고의 기피대상이었다.\n",
    "\n",
    "탈북자들이 북송 전 대기하는 도문변방수용소에 끌려갔는데 며칠 뒤 보위부에서 차를 갖고 건너와 그를 싣고 갔다.\n",
    "\n",
    "그렇지만 그는 예상과는 달리 20일 정도 가수감됐다가 석방됐다. 서류를 보니 중국에 친척이 다 있는 것도 확실하니, 도움 좀 받으려 넘어갔을 뿐이라는 그의 말이 인정됐다. 탈북은 배반이지만, 그의 경우엔 일탈 정도로 간주됐다.\n",
    "\n",
    "보위부라고 해봐야 어차피 한동네 사는 아는 사람들이었는데, 그들은 지역이 배출한 인재의 경력을 망가뜨리고 싶지 않았는지 그다지 혹독하게 대하진 않았다.\n",
    "\n",
    "하지만 허 씨 입장에선 아무 것도 이루지 못하고 잡혀오니 화가 났다. 보위부 감방에서 그는 강 건너편에서 일하다 잡혀왔다는 사람을 알게 됐다. 그는 자기가 일했던 중국 훈춘의 한 슈퍼의 이름을 알려주면서, 다시 건너가 자기 이름을 대면 사장이 고용해 줄 것이라고 했다.\n",
    "\n",
    "감방에서 나온 허 씨는 다시 두만강을 넘었다. 세 번째 탈북이었다. 그는 감옥 동기가 알려준 슈퍼로 갔다. 왕청에 가지 않은 이유는 친척들은 별로 도와줄 의향이 없어 보였기 때문이다.\n",
    "슈퍼는 중국과 나진선봉을 연결하는 도로 옆에 있었는데, 두만강 건너 허 씨네 동네가 약 10㎞ 밖에 빤히 바로 보였다. 허 씨가 내륙 깊이 들어가지 않은 이유는 딸을 데려오고 싶어서였다. 고향 가까이 있어야 집과 연락이 수월하다고 판단했다. 허 씨가 일하는 슈퍼에는 북한을 오가는 운전기사들이 수시로 드나들었다. 이들을 통해 그는 전처에게 휴대전화를 전달할 수 있었다.\n",
    "\n",
    "● 자수해 감옥에 가다\n",
    "그렇게 1년쯤 지났는데 사고가 생겼다. 중국 휴대전화를 받은 전처가 그걸 이용해 돈 벌려고 브로커 일을 하다가 보위부에 체포된 것이다. 전 남편마저 실종되니 보위부는 그녀에게 한국행을 기도했다는 누명을 씌웠다.\n",
    "\n",
    "그 소식이 허 씨에게도 전달됐다. 그래도 4년 간 살았던 정도 있고, 어린 딸까지 있으니 모르는 척 할 수가 없었다. 그는 다시 북에 나가기 위해 자수하기로 결심했다. 자신이 나타나야 전 남편이 한국에 갔다는 누명을 벗길 수 있을 것 같았다.\n",
    "\n",
    "슈퍼 주인은 전과자 출신이었는데, 그가 북으로 가겠다고 하자 감옥에서 나오는 자기의 비법을 전수해주었다. 폐 주변에 황산철을 주사하면 고열이 나고, 염증이 생긴다면서, 자신은 그 방법으로 병원에 호송됐다가 도망쳤다고 했다. 단 이 방법의 단점은 한 달 안에 황산철을 세척하지 못하면 생명을 잃을 수도 있다고 했다.\n",
    "\n",
    "허 씨는 그의 조언에 따라 폐에 황산철을 네 군데나 주입했다. 그리고 스스로 공안에 자수한 뒤 2014년 4월 13일 북송됐다. 그런데 이번은 보위부도 호락호락하지 않았다. 불행하게도 그가 자수한 뒤 공안이 그의 숙소를 뒤져 소지품을 북송할 때 함께 보냈던 것이다. 그 속에는 한국 영사관, 한국인 전도사 등의 전화번호가 적힌 수첩이 있었다. 이게 화근이 됐다. 고문이 시작됐다.\n",
    "\n",
    "중국 사장이 알려준 방법은 확실히 효과가 있었다. 폐가 곪아가기 시작했던 것이다. 염증으로 심한 열까지 나 거동을 못할 정도가 됐다. 보위부는 감방에서 죽이긴 싫었는지 그를 가석방으로 집에 보냈다.\n",
    "\n",
    "그때가 5월 말이었다. 중국 사장이 당부한 폐를 씻어야 하는 한 달이 지난 것이다. 집에 가서 이러저런 치료를 해봤지만 점점 악화됐다. 이렇게 지내다간 죽을 것 같았다. 그는 황산철 주사를 맞은 지 네 달이 지난 8월 23일 다시 중국으로 넘어왔다. 이번엔 하얼빈에 들어가 식당에 취직해 치료에만 전념했다. 하지만 몸은 점점 더 쇠약해졌다.\n",
    "\n",
    "몸을 운신하기 어려워지자 허 씨는 죽더라도 고향에 가서 죽겠다고 생각했다. 그해 11월말 그는 다시 연길에 왔다. 연길에서 혹시나 도움을 받지 않을까 싶어 처음으로 교회에 찾아갔는데, 거기서 집도 제공하고 치료도 해주었다. 12월 말 허 씨는 산소 호흡기에 의지하는 신세가 됐다. 쇼크도 수시로 왔다. 교회에선 한국에 가서 치료를 받아야 살 수 있다며 한국행선을 주선해주었다.\n",
    "\n",
    "\n",
    "교회 목회자가 될 꿈을 꾸던 당시의 허 씨. 2017년 뉴욕에서 찍은 사진이다.\n",
    "\n",
    "\n",
    "● 최초로 남북 측량기사 자격 모두 획득\n",
    "2015년 2월 그는 여러 탈북민들과 함께 한국으로 떠났다. 동남아 정글에서 일행을 따라갈 수 없을 때 친한 동생이 그를 업고 산을 넘었다. 우여곡절 끝에 한국에 도착했지만 다음날 적십자병원에 실려갔다. 이곳에서 4개월 동안 치료를 받다보니 하나원도 나오지 못했다.\n",
    "\n",
    "허 씨는 인천에 거주지가 배정됐다. 건강이 너무 악화돼 일을 할 수 없는 상태라 2016년말까지 병원에 다니며 통원치료를 받았다. 하나원을 나온 다른 사람들이 하나둘 취직해 일자리를 얻는 것을 보고 조급한 마음에 노량진에서 공무원 시험을 준비하기도 했지만, 건강이 악화돼 다시 병원에 실려 가기도 했다. 한국의 의술은 역시 대단했다. 2년이라는 오랜 시간이 걸리긴 했지만, 끝내 허 씨를 완치시켰다.\n",
    "\n",
    "치료 받는 기간에 허 씨는 목회자의 길을 걸어볼까 싶어 1년 남짓 성경공부도 했고, 화장품 회사에 취직해 일도 해봤지만 적성에 맞지 않았다.\n",
    "\n",
    "많은 고민 끝에 북에서 배운 측량기사 일을 다시 해보려 알아보니, 남쪽도 측량기사는 일도 힘들고 보상도 적었다. 그렇지만 적성에 맞지 않는 곳에서 시간을 낭비하는 것보다는 그래도 자신있는 분야를 파보자는 생각에 2018년 한 엔지니어링 회사에 취직했다. 취직은 했어도 아무런 건설기술인 등급도 받지 못했기 때문에 회사에서 가장 많은 나이임에도 허드레 일만 해야 했다. 연봉은 2300만 원이었다. 그는 앞으로 살아가려면 자격증이 필수라는 것을 깨달았다. 어떤 자격을 갖고 있고, 어떤 경력을 쌓는가에 따라 연봉도 결정됐다.\n",
    "\n",
    "허 씨는 회사에 다니며 1년 동안은 토목계측에 대한 용어부터 수첩에 적어 기본적인 지식을 배웠다. 그리고 이듬해 대구과학대에 입학했다. 일도 하면서 대학 공부까지 하려니 야간반을 다닐 수밖에 없었는데, 전국의 측량 관련 야간반 중에 대구가 그나마 가까웠다.\n",
    "\n",
    "가깝다고 해도 당시 일을 하던 포항의 건설현장에서 150㎞나 떨어져 있었다. 일주일에 서너번씩 왕복 300㎞를 달려 수업을 듣고 오는 일은 결코 쉽지 않았다.\n",
    "\n",
    "돌아오는 길에 너무 피곤해 졸음 쉼터에서 쪽잠을 자기 일쑤였다. 잠깐 눈을 붙인다는 것이 해가 중천에 걸릴 때까지 잔적도 있다.\n",
    "\n",
    "허 씨는 대학 공부와 병행해 자격증 시험도 준비했다. 3년 동안 주경야독의 삶을 끈질기게 이어나간 끝에 그는 2022년 대학을 우수한 성적으로 졸업하고, 동시에 측량 및 지형공간정보기사와 토목기사 자격증을 받을 수 있었다. 허 씨는 남과 북에서 측량기사 자격을 각각 받은 최초의 사례다.\n",
    "\n",
    "이러한 자격증과 경력을 인정받아 현재 허 씨는 건설기술인협회에서 고급기술인으로 인정받고 있으며, 300억 원 규모 이상의 토목공사를 책임지고 할 수 있다.\n",
    "\n",
    "\n",
    "2019년 여수에서 전력 케이블용 해저터널 공사장에서 작업하는 모습. 뒷모습이 보이는 사람이 허 씨이다.\n",
    "\n",
    "\n",
    "● “배워야 살 수 있다”\n",
    "허 씨는 김책공대에서 무려 8년이나 공부를 했지만 여기선 모든 것을 다시 배워야 했다고 말했다.\n",
    "\n",
    "“남쪽에 오니 용어는 물론, 장비나 자재 등 모든 것이 북한과 달랐습니다. 비유하면 북에서 통나무로 집을 짓는 법을 배웠는데, 남쪽에 오니 시멘트로 아파트를 짓는 격이죠. 그럼 집 짓는 법을 처음부터 다시 배워야하죠. 물론 북한 김책공대 과정이 전혀 의미 없는 것은 아닙니다. 북한에선 가장 기본적인 것, 즉 공부하는 방법을 배운 것 같습니다.”\n",
    "\n",
    "그는 남북은 통합성에서도 차이가 크다고 했다.\n",
    "\n",
    "“여기는 한 가지를 하려면 열 가지를 알아야 합니다. 많은 것들이 서로 연결돼 있어 전체적으로 진행되죠. 반면 북한은 직무가 매우 세분화돼 있고, 맡겨진 것만 하면 됐어요.”\n",
    "\n",
    "자격증과 경력을 쌓고 나니 연봉도 빠르게 올라갔다. 김책공대까지 입학했던 북한 시골 수재가 다시 자신의 두뇌와 재능을 발휘하는 데는 오랜 시간이 걸리지 않았다. 2300만 원에서 시작했던 연봉은 6년 만에 3배 이상 높아졌다.\n",
    "\n",
    "그는 여기에 만족하지 않았다. 그는 올해 3월 다시 대구대 공간정보전문기술 석사과정에 입학했다. 토질 및 기초기술사 자격을 취득하기 위해서다. 다른 자격증과는 달리 이 자격은 받기가 매우 어렵다. 허 씨의 계획은 향후 5년 안에 석사와 함께 기술사 자격을 획득하는 것이다.\n",
    "\n",
    "그렇다고 공부만 할 수는 없는 일. 요즘 허 씨는 마산만에서 스팀배관 부설을 위한 해저터널을 뚫는 작업을 하고 있다. 그의 직책은 공사차장. 터널 시공 품질을 총괄하는 중요한 자리다.\n",
    "\n",
    "건설 현장은 매우 거칠고 다툼도 많다. 외국인 근로자들도 많아 의사소통의 문제도 많다. 많은 어려움이 있지만 허 씨는 포기하지 않고 한 걸음씩 나가고 있다.\n",
    "\n",
    "“거친 현장이라서 그런지 북에서 왔다고 우습게 보는 사람들이 많아요. 아직도 저는 ‘나는 여전히 이방인이구나’라는 생각을 하고 있습니다. 그렇지만 실력은 남에게 뒤진다고 생각하지 않습니다. 여러 곳에서 이직 제안도 많이 받습니다.”\n",
    "\n",
    "2023년 남북하나재단이 주관한 정착사례 발표대회에서 그는 최우수상인 통일부 장관상을 받았다. 하지만 허 씨는 지금은 정착의 첫 발자국을 뗀 것에 불과하다고 했다.\n",
    "\n",
    "그는 자신의 이름으로 회사를 만들어 키우는 것을 다음 목표로 정했다. 그 목표가 달성되면 또 할 일이 있다. 나아가 통일이 되면 할 계획도 미리 생각해두었다.\n",
    "\n",
    "“저는 북에 돌아가 여기서 배운 기술을 북에 전수할 겁니다. 한국은 토목 공사를 할 때 측량, 시공, 품질까지 다 알아야 합니다. 통일 되면 교통인프라를 다시 정리해야 할 것인데, 북한에서 대학을 다녔던 동창들은 통합성에 있어 크게 떨어집니다. 이런 것을 가르쳐야죠. 그리고 남북에서 모두 측량기사 자격을 받은 유일한 사람이니 다른 꿈도 있습니다. 남북공간정보 통합지도체계를 만드는 것도 중요한 목표입니다.”\n",
    "\n",
    "꿈을 말할 때 그는 가장 행복한 표정이었다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLYernGNhZFh"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# 텍스트를 600자 단위로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.create_documents([script])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tvsH5lXJmgRE",
    "outputId": "06a44ba2-d89b-4984-a164-3a6f6068b767"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kexR2evmh0C",
    "outputId": "48358e95-7b0f-4177-cac2-153d8d01ca55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='허수현은 한반도 최북단 탄광마을이 낳은 수재였다. 그는 고등학교 졸업 직전 북한 전체에서 700명에게만 수여하는 ‘7.15 최우등상’을 수상했다. 7.15최우등상은 김정일이 평양 남산고급중학교를 졸업한 날인 1960년 7월 15일을 기념해 1987년에 만들어진 상이다.\\n\\n지금은 이 상이 특권층 자식들을 대학에 보내기 위한 발판이 돼 각종 비리와 뇌물로 얼룩져 있지만, 상이 제정된 초기 몇 년은 정말 공부 잘하는 사람에게만 수여됐다. 상을 받게 되면 곧바로 중앙급 대학에 진학할 수 있었다. 북한에선 고등중학교 졸업생 중 20% 미만이 대학이나 전문학교에 갈 수 있다는 것을 감안하면 엄청난 특혜였다.\\n\\n허 씨도 김책공업종합대학(김책공대)에 입학해 8년이나 공부했다. 그리고 그때 배운 지식을 활용해 지금은 한반도 최남단인 경남 마산의 해저터널 공사장에서 시공품질을 관리하는 공사차장으로 일하고 있다. 김책공대 졸업생이 네 번의 탈북을 반복한 뒤 건강이 악화돼 남의 등에 업혀 동남아 정글을 넘어 한국까지 오게 되고, 이후 남과 북에서 동시에 측량기사 자격을 받은 최초의 기술자가 돼 해저터널 공사장에서 일하게 되기까지 삶의 과정은 결코 순탄하지 않았다.')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De0c3HT7jXSx"
   },
   "outputs": [],
   "source": [
    "# Chroma 를 통해 벡터 저장소 생성\n",
    "chroma_db = Chroma.from_documents(texts, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iMjLKY7anCiV",
    "outputId": "cc08d5fe-e6c8-443d-ecd2-2470b89cd2ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색(쿼리)\n",
    "similar_docs = chroma_db.similarity_search(\"주인공은 어디서 태어났는가?\")\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCDtbepAnO5r"
   },
   "source": [
    "## 5-3. VectorStoreRetriever: as_retreiver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaSx-6xpnSBQ"
   },
   "source": [
    "`VectorStoreRetreiver`는 벡터 저장소를 사용하여 문서를 검색하는 Retriever 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pfIz5uBnHNB",
    "outputId": "a5c09d00-3e9c-4494-811b-e1da2c7f6919"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-273597ce08cc>:5: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 4\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n"
     ]
    }
   ],
   "source": [
    "# retriever 생성\n",
    "retriever = chroma_db.as_retriever()\n",
    "\n",
    "# similarity_search 를 통해 유사도 높은 1개 문서를 검색\n",
    "relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n",
    "\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf4y4xdJnhus",
    "outputId": "dfb73fc8-907b-405c-8cd5-eaf02bf4bb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 1\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n"
     ]
    }
   ],
   "source": [
    "# retriever 생성\n",
    "retriever = chroma_db.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# similarity_search 를 통해 유사도 높은 1개 문서를 검색\n",
    "relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n",
    "\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46SkVtFonnTw"
   },
   "source": [
    "**search_type**  \n",
    "search_type 매개변수에 검색 알고리즘을 지정할 수 있습니다.\n",
    "\n",
    "- similarity(기본값), mmr, similarity_score_threshold 등의 옵션을 지정할 수 있습니다.\n",
    "- 아래에서 지정 옵션 별 차이에 대해 다룹니다.\n",
    "search_type='similarity'\n",
    "\n",
    "기본 값으로 설정되어 있습니다. vector store 의 유사도 알고리즘 기반으로 상위 K개의 문서를 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iX-1pHonjyB",
    "outputId": "dbe78a95-7a6d-4592-cf40-eb95b3953b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
      "============================================================\n",
      "32살 때인 2006년 그는 10살 어린 여성과 결혼했다. 아내는 탄광 선전대 가수로 나름 인기가 좋았다. 이성적인 지식인과 감성적인 예술인의 조합이었다.\n",
      "\n",
      "그렇지만 매력과 결혼생활은 별개였다. 결혼한 직후부터 둘은 다투는 일이 많았다. 서로가 서로를 견디기 어려워했다. 4년간의 결혼생활 끝에 둘은 이혼하기로 합의했다. 어린 딸은 아내가 키우기로 했다. 이때부터 그는 중국으로 눈을 돌렸다.\n",
      "\n",
      "\n",
      "2022년 인천지하철 공사 현장에서 일하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 두만강을 넘나들다\n",
      "강 건너 연변 왕청에는 아버지의 삼촌과 사촌 등 친척들이 살고 있었다. 국경 근처라 많은 사람들이 중국을 드나들 때도 허 씨는 명색이 김책공대 졸업생인데 조국을 배반하면 안 된다는 마음이 컸다. 하지만 이혼 후 세상이 달리 보이기 시작했다. 이혼까지 한 마당에 눈치 볼 일도, 무서울 일도 없었다.\n",
      "\n",
      "2010년 겨울 그는 국경경비대에 돈을 쥐어주고 두만강을 넘었다. 탈북한 것은 아니고, 친척에게 도움만 받자는 목적이었다. 저녁에 넘어가서 친척에게 전화를 하고 새벽이 되기 전에 다시 북으로 넘어왔다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
    "relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob00rl4wn2sR"
   },
   "source": [
    "**Maximal Marginal Relevance(MMR) 검색**\n",
    "\n",
    "MMR은 쿼리와 관련된 항목을 검색하면서 동시에 내용의 중복을 최소화하는 기법입니다.\n",
    "\n",
    "이 방법은 단순히 관련성이 높은 항목들을 선택하는 대신, 관련성과 다양성 사이의 균형을 찾는 데 중점을 둡니다.\n",
    "\n",
    "**MMR 에 대해 이해해보기**\n",
    "\n",
    "모임에 참석해 친구를 위해 새로운 사람들을 소개하는 상황을 상상해 보세요. 친구가 만나고 싶어하는 사람들의 특징(embedding vector)을 알고 있습니다.\n",
    "\n",
    "MMR 방식을 적용하면 다음과 같은 접근법을 사용합니다:\n",
    "\n",
    "1. 모임에 있는 모든 사람들의 프로필(list of embedding vector)을 살펴봅니다.\n",
    "2. 친구의 관심사와 특성에 부합하는 사람을 찾아 소개합니다.\n",
    "3. 그 후, 다시 참여한 사람들을 살펴보되, 이번에는 이미 소개한 사람과는 다른 특성을 가진 사람을 찾습니다.\n",
    "4. 여기서 lambda mult 매개변수는 친구의 취향과 새로운 특성 사이의 균형을 조정하는 역할을 합니다.\n",
    "5. 이 과정을 친구가 만나길 원하는 사람들의 수(k 매개변수)에 도달할 때까지 반복합니다.\n",
    "6. 마지막으로, 친구가 만난 사람들의 목록을 제공합니다.  \n",
    "\n",
    "이 예시를 통해 MMR이 **관련성 높은 항목을 선택** 하는 동시에 **내용의 다양성을 유지**하려는 방식을 이해할 수 있습니다.\n",
    "\n",
    "**search_type='mmr'**을 통해 MMR 을 사용한 검색을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vopfkF6vn0ud",
    "outputId": "d2c29150-91eb-4e5d-deba-77fe4afba082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
      "============================================================\n",
      "“저는 졸업장을 받고 나니, 3점짜리 과목이 몇 개 있었어요. 저는 대학 내내 3점을 받은 적이 없거든요. 5점 만점에 3점은 낙제를 겨우 면한 수준인데, 대학 교무부에 찾아가 싸우지도 않았어요. 어차피 이 체제가 싫어서 탈북하려 결심한 마당에 3점이 대수냐고 생각했죠.”\n",
      "\n",
      "“저도 졸업증에 받지 않은 3점들이 있었어요. 권력자 부모를 둔 학생들은 좋은 곳에 가기 위해 대학 교무부 직원들에게 뇌물을 주고 컴퓨터에서 점수를 바꾸었어요. 5점 최우등생과, 4점 우등생, 3점 보통생의 전체 비율을 바꿀 수 없으니 5점으로 조작하려면 누군가의 점수를 빼앗아야 했죠. 제일 힘이 없는 우리가 점수를 빼앗긴 거였죠.”\n",
      "\n",
      "최우등을 하고도, 돈과 권력이 없으면 3점 졸업증을 받아야 했던 시대. 허 씨와 기자는 그 시대에 평양에서 대학을 다녔다. 기숙사에서 밥을 몇 숟가락만 주던 때라 대학 시절을 떠올리면 배고팠던 기억밖에 없다. 졸업증을 받은 것만으로도 기적이었다. 뇌물로 성적을 조작하고, 남의 졸업논문을 베껴 써서 제출하는 상황은 지금도 별반 나아지진 않았다.\n",
      "\n",
      "\n",
      "2018년 뉴질랜드로 한 달 동안 어학연수를 떠났던 시기의 모습.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
    "relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz_RVZbIocJN"
   },
   "source": [
    "search_type='similarity_score_threshold' 을 지정하면 score_threshold 기준을 충족하는 유사도 문서가 반환됩니다.\n",
    "\n",
    "만약 {\"k\": 3} 이지만, {\"score_threshold\": 0.5} 로 설정되었는데 score 가 0.5를 넘는 문서가 2개 밖에 없다면, 결과는 3개 문서가 아닌 2개 문서가 반환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EI7TtkpoZ24",
    "outputId": "d84d0c09-60a7-4d18-fee9-0c96b3735a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
      "============================================================\n",
      "32살 때인 2006년 그는 10살 어린 여성과 결혼했다. 아내는 탄광 선전대 가수로 나름 인기가 좋았다. 이성적인 지식인과 감성적인 예술인의 조합이었다.\n",
      "\n",
      "그렇지만 매력과 결혼생활은 별개였다. 결혼한 직후부터 둘은 다투는 일이 많았다. 서로가 서로를 견디기 어려워했다. 4년간의 결혼생활 끝에 둘은 이혼하기로 합의했다. 어린 딸은 아내가 키우기로 했다. 이때부터 그는 중국으로 눈을 돌렸다.\n",
      "\n",
      "\n",
      "2022년 인천지하철 공사 현장에서 일하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 두만강을 넘나들다\n",
      "강 건너 연변 왕청에는 아버지의 삼촌과 사촌 등 친척들이 살고 있었다. 국경 근처라 많은 사람들이 중국을 드나들 때도 허 씨는 명색이 김책공대 졸업생인데 조국을 배반하면 안 된다는 마음이 컸다. 하지만 이혼 후 세상이 달리 보이기 시작했다. 이혼까지 한 마당에 눈치 볼 일도, 무서울 일도 없었다.\n",
      "\n",
      "2010년 겨울 그는 국경경비대에 돈을 쥐어주고 두만강을 넘었다. 탈북한 것은 아니고, 친척에게 도움만 받자는 목적이었다. 저녁에 넘어가서 친척에게 전화를 하고 새벽이 되기 전에 다시 북으로 넘어왔다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 2, \"score_threshold\": 0.5},\n",
    ")\n",
    "relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqD0J2cXonAc"
   },
   "source": [
    "**search_kwargs**\n",
    "search_kwargs에 다양한 옵션을 지정할 수 있습니다.\n",
    "\n",
    "다음의 search_kwargs 로 Retriever 의 검색 결과를 세부조정할 수 있습니다.\n",
    "\n",
    "* k: \"k\" 매개변수로 찾을 문서의 개수를 지정할 수 있습니다. 만약, {\"k\": 3} 지정한다면 3개의 유사도 높은 문서만 선택하겠다는 의미 입니다. 기본 값은 1입니다.\n",
    "* score_threshold: Minimum relevance threshold for similarity_score_threshold\n",
    "* fetch_k: Amount of documents to pass to MMR algorithm (Default: 20)\n",
    "* lambda_mult: Diversity of results returned by MMR. 1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
    "* filter: document를 메타데이터 기준으로 필터링 합니다. (예시) search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01FtVz85oh_o",
    "outputId": "c8eebbb0-8335-415b-a373-811a64c8bff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 2\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
      "============================================================\n",
      "32살 때인 2006년 그는 10살 어린 여성과 결혼했다. 아내는 탄광 선전대 가수로 나름 인기가 좋았다. 이성적인 지식인과 감성적인 예술인의 조합이었다.\n",
      "\n",
      "그렇지만 매력과 결혼생활은 별개였다. 결혼한 직후부터 둘은 다투는 일이 많았다. 서로가 서로를 견디기 어려워했다. 4년간의 결혼생활 끝에 둘은 이혼하기로 합의했다. 어린 딸은 아내가 키우기로 했다. 이때부터 그는 중국으로 눈을 돌렸다.\n",
      "\n",
      "\n",
      "2022년 인천지하철 공사 현장에서 일하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 두만강을 넘나들다\n",
      "강 건너 연변 왕청에는 아버지의 삼촌과 사촌 등 친척들이 살고 있었다. 국경 근처라 많은 사람들이 중국을 드나들 때도 허 씨는 명색이 김책공대 졸업생인데 조국을 배반하면 안 된다는 마음이 컸다. 하지만 이혼 후 세상이 달리 보이기 시작했다. 이혼까지 한 마당에 눈치 볼 일도, 무서울 일도 없었다.\n",
      "\n",
      "2010년 겨울 그는 국경경비대에 돈을 쥐어주고 두만강을 넘었다. 탈북한 것은 아니고, 친척에게 도움만 받자는 목적이었다. 저녁에 넘어가서 친척에게 전화를 하고 새벽이 되기 전에 다시 북으로 넘어왔다.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "retriever = chroma_db.as_retriever(\n",
    "    search_type=\"mmr\", search_kwargs={\"k\": 2, \"fetch_k\": 10, \"lambda_mult\": 0.75}\n",
    ")\n",
    "relevant_docs = retriever.get_relevant_documents(\"주인공은 어디서 태어났는가?\")\n",
    "print(f\"문서의 개수: {len(relevant_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "for i in range(len(relevant_docs)):\n",
    "    print(relevant_docs[i].page_content)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zSCmIlYpDnW"
   },
   "source": [
    "## 5-4. FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-CR4n-xphs8",
    "outputId": "731b0f86-3be0-4b85-91a9-0aadb8d43c24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp3HtvOspHxT"
   },
   "source": [
    "FAISS는 semantic search를 도와주는 Meta(구 Facebook)에서 만든 라이브러리 입니다.\n",
    "\n",
    "* 링크: https://github.com/facebookresearch/faiss\n",
    "리이선스는 **MIT License** 입니다.\n",
    "\n",
    "**[참고]**\n",
    "\n",
    "MIT 라이선스는 자유롭고 유연한 소프트웨어 라이선스 중 하나입니다. MIT 라이선스 하에 배포된 소프트웨어는 **상업적으로 이용**할 수 있습니다\n",
    "\n",
    "주요 특징은 다음과 같습니다:\n",
    "\n",
    "* 간결함과 넓은 범위의 사용 허가: MIT 라이선스는 매우 간결하며, 사용자에게 소프트웨어를 거의 제한 없이 사용, 복사, 수정, 합병, 출판, 배포, 하위 라이선스 부여, 판매할 수 있는 권리를 부여합니다.\n",
    "\n",
    "* 저작권과 라이선스 고지 유지 요구: 라이선스는 사용자가 MIT 라이선스하에 배포된 모든 복사본과 상당한 부분에 원래의 저작권 고지와 이 라이선스 고지를 포함하도록 요구합니다.\n",
    "\n",
    "* 책임의 부인: MIT 라이선스는 소프트웨어가 '있는 그대로' 제공되며, 소프트웨어의 사용으로 인한 어떠한 보증도 제공하지 않습니다. 이는 소프트웨어 사용으로 인한 모든 위험은 사용자가 부담한다는 것을 의미합니다.\n",
    "\n",
    "MIT 라이선스는 그 간결함과 유연성으로 인해 많은 오픈 소스 프로젝트와 상업적 프로젝트에서 널리 사용됩니다. 이 라이선스는 소프트웨어 개발자가 자신의 소프트웨어를 거의 제한 없이 공유할 수 있도록 해주며, 소프트웨어 산업 전반에 걸쳐 협력과 혁신을 촉진하는 데 기여하고 있습니다.\n",
    "\n",
    "API 사용방법은 Chroma와 동일합니다. (동일한 인터페이스를 제공합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvVl2-H9pGZI"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# 텍스트를 600자 단위로 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=0)\n",
    "\n",
    "texts = text_splitter.create_documents([script])\n",
    "\n",
    "faiss_db = FAISS.from_documents(texts, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZujfUOTpfdR",
    "outputId": "86cff18c-7517-4f95-fba1-065afef67ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 개수: 4\n",
      "[검색 결과]\n",
      "\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검색(쿼리)\n",
    "similar_docs = faiss_db.similarity_search(\"주인공은 어디서 태어났는가?\")\n",
    "\n",
    "print(f\"문서의 개수: {len(similar_docs)}\")\n",
    "print(\"[검색 결과]\\n\")\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPIB6_3eqg4h"
   },
   "outputs": [],
   "source": [
    "# 데이터베이스를 검색기로 사용하기 위해 retriever 변수에 할당합니다.\n",
    "retriever = faiss_db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5nvi9mCqm62"
   },
   "outputs": [],
   "source": [
    "# 검색 질의를 사용하여 관련 문서를 검색합니다.\n",
    "query = \"주인공은 어디서 태어났는가?\"\n",
    "docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRdJUAigqqgJ",
    "outputId": "3479bb93-eb16-4083-ec1c-4ae133783e6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n"
     ]
    }
   ],
   "source": [
    "# docs 리스트의 첫 번째 요소의 page_content 속성을 출력합니다.\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqrkKLopqtCA"
   },
   "source": [
    "FAISS에는 몇 가지 특정 메서드가 있습니다.\n",
    "\n",
    "그 중 하나는 similarity_search_with_score로, 문서뿐만 아니라 쿼리와 문서 간의 거리 점수도 반환할 수 있습니다.\n",
    "\n",
    "반환되는 거리 점수는 L2 거리입니다. 따라서 점수가 낮을수록 더 좋은 결과 입니다.\n",
    "\n",
    "db.similarity_search_with_score(query) 메서드를 사용하여 질의와 유사한 문서를 검색하고 유사도 점수와 함께 반환합니다.\n",
    "\n",
    "반환된 결과는 (문서, 점수) 튜플의 리스트 형태로 구성됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iQ95noxNqtyD",
    "outputId": "29d34a4a-4999-4407-e6d2-2f2c39547e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Content]\n",
      "2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\n",
      "\n",
      "\n",
      "● 신분 상승의 꿈\n",
      "그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\n",
      "\n",
      "온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\n",
      "\n",
      "탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\n",
      "부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.\n",
      "\n",
      "[Score]\n",
      "0.33392143\n"
     ]
    }
   ],
   "source": [
    "# 쿼리와 유사한 문서를 검색하고 유사도 점수와 함께 반환합니다.\n",
    "docs_and_scores = faiss_db.similarity_search_with_score(query)\n",
    "content, score = docs_and_scores[0]  # 문서와 점수 리스트에서 첫 번째 요소를 선택합니다\n",
    "print(\"[Content]\")\n",
    "print(content.page_content)  # 선택된 문서의 page_content 속성을 출력합니다\n",
    "print(\"\\n[Score]\")\n",
    "print(score)  # 선택된 문서의 점수를 출력합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15eJins_qzSJ"
   },
   "source": [
    "similarity_search_by_vector 함수를 사용하면 주어진 임베딩 벡터와 유사한 문서를 검색할 수 있습니다.\n",
    "\n",
    "이 함수는 문자열 대신 임베딩 벡터를 매개변수로 받아들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2_6B6-eq0hx",
    "outputId": "6b451fa8-ec42-457b-b7bb-42090912ef6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='2021년 강원도 동해시 한 아파트 공사장에서 시공 측량 작업을 진행하고 있는 허 씨.\\n\\n\\n● 신분 상승의 꿈\\n그가 태어난 한반도 최북단 온성군은 오랜 역사를 가지고 있다. 세종 22년인 1440년에 김종서 장군이 이곳을 평정한 뒤 군을 설치하고 온성이라 부르기 시작했다.\\n\\n온성에는 평안남도 안주 탄전에 이은 북한 최대의 갈탄 탄전이 있다. 1980년대까지만 해도 온성에는 연간 50만 톤 이상의 갈탄을 생산하는 탄광이 여러 개 있었다. 허 씨는 이런 대형 탄광 중 하나인 주원 탄광마을에서 1974년에 태어났다.\\n\\n탄광에서 일하는 사람들은 대개 출신성분이 나빴다. 허 씨의 부친도 마찬가지였다. 부친은 1960년대 후반까지 중국에서 살다가 문화대혁명 등의 격변기를 거치며 북한으로 넘어왔다.\\n부친은 늘 허 씨에게 “너는 공부를 잘해 꼭 신분 상승을 해야 한다”고 말했다. 허 씨가 13세 때 부친은 갱이 붕괴돼 사망했다. 탄광마을에선 자주 일어나는 일이었다.')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질의를 임베딩 벡터로 변환합니다.\n",
    "query = \"주인공은 어디서 태어났는가?\"\n",
    "embedding_vector = embeddings.embed_query(query)\n",
    "# 임베딩 벡터를 사용하여 유사도 검색을 수행하고, 문서와 점수를 반환합니다.\n",
    "docs_and_scores = faiss_db.similarity_search_by_vector(embedding_vector)\n",
    "docs_and_scores[0]  # 문서와 점수 리스트에서 첫 번째 요소를 선택합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4pFVjocrWEG"
   },
   "source": [
    "## 5-6. 앙상블 검색기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8Xd4IMwrrKv",
    "outputId": "ee775cbe-1d81-4d29-9392-f4fdca40af15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVL-O-UmrZXQ"
   },
   "source": [
    "EnsembleRetriever는 여러 retriever를 입력으로 받아 get_relevant_documents() 메서드의 결과를 앙상블하고, Reciprocal Rank Fusion 알고리즘을 기반으로 결과를 재순위화합니다.\n",
    "\n",
    "서로 다른 알고리즘의 장점을 활용함으로써, EnsembleRetriever는 단일 알고리즘보다 더 나은 성능을 달성할 수 있습니다.\n",
    "\n",
    "가장 일반적인 패턴은 sparse retriever (예: BM25)와 dense retriever (예: embedding similarity)를 결합하는 것인데, 이는 두 retriever의 장점이 상호 보완적이기 때문입니다. 이를 \"hybrid search\" 라고도 합니다.\n",
    "\n",
    "Sparse retriever는 키워드를 기반으로 관련 문서를 찾는 데 효과적이며, dense retriever는 의미적 유사성을 기반으로 관련 문서를 찾는 데 효과적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwqL1IQMrXy_"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXZsOOo0rlt5"
   },
   "source": [
    "두 개의 문서 리스트(doc_list_1과 doc_list_2)를 정의합니다.  \n",
    "EnsembleRetriever를 초기화하여 BM25Retriever와 FAISS 검색기를 결합합니다. 각 검색기의 가중치를 설정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqwUin1bq6wg"
   },
   "outputs": [],
   "source": [
    "# 비타민 별 섭취할 수 있는 음식 정보\n",
    "doc_list_1 = [\n",
    "    \"비타민A : 당근, 시금치, 감자 등의 주황색과 녹색 채소에서 섭취할 수 있습니다.\",\n",
    "    \"비타민B : 전곡물, 콩, 견과류, 육류 등 다양한 식품에서 찾을 수 있습니다.\",\n",
    "    \"비타민C : 오렌지, 키위, 딸기, 브로콜리, 피망 등의 과일과 채소에 많이 들어 있습니다.\",\n",
    "    \"비타민D : 연어, 참치, 버섯, 우유, 계란 노른자 등에 함유되어 있습니다.\",\n",
    "    \"비타민E : 해바라기씨, 아몬드, 시금치, 아보카도 등에서 섭취할 수 있습니다.\",\n",
    "]\n",
    "\n",
    "# 비타민 별 효능 정보\n",
    "doc_list_2 = [\n",
    "    \"비타민A : 시력과 피부 건강을 지원합니다.\",\n",
    "    \"비타민B : 에너지 대사와 신경계 기능을 돕습니다.\",\n",
    "    \"비타민C : 면역 체계를 강화하고 콜라겐 생성을 촉진합니다.\",\n",
    "    \"비타민D : 뼈 건강과 면역 체계를 지원합니다.\",\n",
    "    \"비타민E : 항산화 작용을 통해 세포를 보호합니다.\",\n",
    "]\n",
    "\n",
    "\n",
    "# bm25 retriever와 faiss retriever를 초기화합니다.\n",
    "bm25_retriever = BM25Retriever.from_texts(\n",
    "    # doc_list_1의 텍스트와 메타데이터를 사용하여 BM25Retriever를 초기화합니다.\n",
    "    doc_list_1,\n",
    "    metadatas=[{\"source\": 1}] * len(doc_list_1),\n",
    ")\n",
    "bm25_retriever.k = 1  # BM25Retriever의 검색 결과 개수를 1로 설정합니다.\n",
    "\n",
    "embedding = OpenAIEmbeddings()  # OpenAI 임베딩을 사용합니다.\n",
    "faiss_vectorstore = FAISS.from_texts(\n",
    "    # doc_list_2의 텍스트와 임베딩, 메타데이터를 사용하여 FAISS 벡터 저장소를 초기화합니다.\n",
    "    doc_list_2,\n",
    "    embedding,\n",
    "    metadatas=[{\"source\": 2}] * len(doc_list_2),\n",
    ")\n",
    "# FAISS 벡터 저장소를 사용하여 retriever를 생성하고, 검색 결과 개수를 1로 설정합니다.\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "# 앙상블 retriever를 초기화합니다.\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    # BM25Retriever와 FAISS retriever를 사용하여 EnsembleRetriever를 초기화하고, 각 retriever의 가중치를 0.6:0.4로 설정합니다.\n",
    "    retrievers=[bm25_retriever, faiss_retriever],\n",
    "    weights=[0.6, 0.4],\n",
    "    search_type=\"mmr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAhQJ7Los5gl"
   },
   "source": [
    "ensemble_retriever 객체의 get_relevant_documents() 메서드를 호출하여 관련성 높은 문서를 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHQVMtECs4QL",
    "outputId": "62fff9e1-8eac-4c2e-8cfc-7d33bebdfb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ensemble Retriever]\n",
      " [Document(metadata={'source': 1}, page_content='비타민A : 당근, 시금치, 감자 등의 주황색과 녹색 채소에서 섭취할 수 있습니다.'), Document(metadata={'source': 2}, page_content='비타민A : 시력과 피부 건강을 지원합니다.')]\n",
      "\n",
      "[BM25 Retriever]\n",
      " [Document(metadata={'source': 1}, page_content='비타민A : 당근, 시금치, 감자 등의 주황색과 녹색 채소에서 섭취할 수 있습니다.')]\n",
      "\n",
      "[FAISS Retriever]\n",
      " [Document(metadata={'source': 2}, page_content='비타민A : 시력과 피부 건강을 지원합니다.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 문서를 가져옵니다.\n",
    "query = \"비타민A 의 효능은?\"\n",
    "ensemble_result = ensemble_retriever.get_relevant_documents(query)\n",
    "bm25_result = bm25_retriever.get_relevant_documents(query)\n",
    "faiss_result = faiss_retriever.get_relevant_documents(query)\n",
    "\n",
    "# 가져온 문서를 출력합니다.\n",
    "print(\"[Ensemble Retriever]\\n\", ensemble_result, end=\"\\n\\n\")\n",
    "print(\"[BM25 Retriever]\\n\", bm25_result, end=\"\\n\\n\")\n",
    "print(\"[FAISS Retriever]\\n\", faiss_result, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2pcU8zUs_yu",
    "outputId": "ceddc736-5dc9-40d9-8019-42df7ae20706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ensemble Retriever]\n",
      " [Document(metadata={'source': 1}, page_content='비타민E : 해바라기씨, 아몬드, 시금치, 아보카도 등에서 섭취할 수 있습니다.'), Document(metadata={'source': 2}, page_content='비타민A : 시력과 피부 건강을 지원합니다.')]\n",
      "\n",
      "[BM25 Retriever]\n",
      " [Document(metadata={'source': 1}, page_content='비타민E : 해바라기씨, 아몬드, 시금치, 아보카도 등에서 섭취할 수 있습니다.')]\n",
      "\n",
      "[FAISS Retriever]\n",
      " [Document(metadata={'source': 2}, page_content='비타민A : 시력과 피부 건강을 지원합니다.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 문서를 가져옵니다.\n",
    "query = \"시력에 좋은 비타민은?\"\n",
    "ensemble_result = ensemble_retriever.get_relevant_documents(query)\n",
    "bm25_result = bm25_retriever.get_relevant_documents(query)\n",
    "faiss_result = faiss_retriever.get_relevant_documents(query)\n",
    "\n",
    "# 가져온 문서를 출력합니다.\n",
    "print(\"[Ensemble Retriever]\\n\", ensemble_result, end=\"\\n\\n\")\n",
    "print(\"[BM25 Retriever]\\n\", bm25_result, end=\"\\n\\n\")\n",
    "print(\"[FAISS Retriever]\\n\", faiss_result, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AM2PbbDOs_67",
    "outputId": "9a1ee576-81ca-48e1-e33f-987609fc6731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ensemble Retriever]\n",
      " [Document(metadata={'source': 1}, page_content='비타민E : 해바라기씨, 아몬드, 시금치, 아보카도 등에서 섭취할 수 있습니다.'), Document(metadata={'source': 2}, page_content='비타민E : 항산화 작용을 통해 세포를 보호합니다.')]\n",
      "\n",
      "[BM25 Retriever]\n",
      " [Document(metadata={'source': 1}, page_content='비타민E : 해바라기씨, 아몬드, 시금치, 아보카도 등에서 섭취할 수 있습니다.')]\n",
      "\n",
      "[FAISS Retriever]\n",
      " [Document(metadata={'source': 2}, page_content='비타민E : 항산화 작용을 통해 세포를 보호합니다.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 검색 결과 문서를 가져옵니다.\n",
    "query = \"비타민E 는 어떻게 섭취할 수 있나요?\"\n",
    "ensemble_result = ensemble_retriever.get_relevant_documents(query)\n",
    "bm25_result = bm25_retriever.get_relevant_documents(query)\n",
    "faiss_result = faiss_retriever.get_relevant_documents(query)\n",
    "\n",
    "# 가져온 문서를 출력합니다.\n",
    "print(\"[Ensemble Retriever]\\n\", ensemble_result, end=\"\\n\\n\")\n",
    "print(\"[BM25 Retriever]\\n\", bm25_result, end=\"\\n\\n\")\n",
    "print(\"[FAISS Retriever]\\n\", faiss_result, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
